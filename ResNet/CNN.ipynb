{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1354,
     "status": "ok",
     "timestamp": 1593194711200,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "nr9wvs88cT_z",
    "outputId": "bd5da9ef-0f1d-4251-92aa-4cba509b27ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12677,
     "status": "ok",
     "timestamp": 1593194722535,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "9QT2WHYLcq6C"
   },
   "outputs": [],
   "source": [
    "!cp '/content/drive/My Drive/tumor dataset.zip' .\n",
    "!unzip -qq 'tumor dataset.zip' -d . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12670,
     "status": "ok",
     "timestamp": 1593194722536,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "cLcZ2BWMypNy"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "# shutil.rmtree(\"/content/new\")\n",
    "os.mkdir(\"/content/new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3377,
     "status": "ok",
     "timestamp": 1593194728541,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "ib1DAPDREKKA"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/ML_BIO_HW5/HW10')\n",
    "import crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5509,
     "status": "ok",
     "timestamp": 1593194731593,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "u4U3vjiYdkoq",
    "outputId": "f86dbce7-51f4-40ab-b6ee-c0f57a903bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "/content/new/0.jpg\n",
      "(218, 180, 3)\n",
      "(218, 180)\n",
      "(1, 165, 137)\n",
      "/content/new/1.jpg\n",
      "(360, 319)\n",
      "(360, 319)\n",
      "(1, 359, 318)\n",
      "/content/new/2.jpg\n",
      "(348, 287, 3)\n",
      "(348, 287)\n",
      "(1, 300, 229)\n",
      "/content/new/3.jpg\n",
      "(336, 300)\n",
      "(336, 300)\n",
      "(1, 300, 243)\n",
      "/content/new/4.jpg\n",
      "(630, 587, 3)\n",
      "(630, 587)\n",
      "(1, 627, 525)\n",
      "/content/new/5.jpg\n",
      "(993, 825, 3)\n",
      "(993, 825)\n",
      "(1, 982, 789)\n",
      "/content/new/6.jpg\n",
      "(890, 700, 3)\n",
      "(890, 700)\n",
      "(1, 889, 662)\n",
      "/content/new/7.jpg\n",
      "(246, 205, 3)\n",
      "(246, 205)\n",
      "(1, 232, 161)\n",
      "/content/new/8.jpg\n",
      "(253, 200, 3)\n",
      "(253, 200)\n",
      "(1, 245, 197)\n",
      "/content/new/9.jpg\n",
      "(512, 512, 3)\n",
      "(512, 512)\n",
      "(1, 417, 352)\n",
      "/content/new/10.jpg\n",
      "(1200, 1059, 3)\n",
      "(1200, 1059)\n",
      "(1, 1054, 812)\n",
      "/content/new/11.jpg\n",
      "(279, 258, 3)\n",
      "(279, 258)\n",
      "(1, 278, 257)\n",
      "/content/new/12.jpg\n",
      "(369, 400, 3)\n",
      "(369, 400)\n",
      "(1, 358, 388)\n",
      "/content/new/13.jpg\n",
      "(324, 272, 3)\n",
      "(324, 272)\n",
      "(1, 323, 271)\n",
      "/content/new/14.jpg\n",
      "(366, 310, 3)\n",
      "(366, 310)\n",
      "(1, 340, 298)\n",
      "/content/new/15.jpg\n",
      "(312, 254, 3)\n",
      "(312, 254)\n",
      "(1, 298, 242)\n",
      "/content/new/16.jpg\n",
      "(249, 178, 3)\n",
      "(249, 178)\n",
      "(1, 181, 134)\n",
      "/content/new/17.jpg\n",
      "(298, 260, 3)\n",
      "(298, 260)\n",
      "(1, 228, 191)\n",
      "/content/new/18.jpg\n",
      "(269, 249, 3)\n",
      "(269, 249)\n",
      "(1, 223, 219)\n",
      "/content/new/19.jpg\n",
      "(310, 246, 3)\n",
      "(310, 246)\n",
      "(1, 244, 195)\n",
      "/content/new/20.jpg\n",
      "(500, 377)\n",
      "(500, 377)\n",
      "(1, 477, 366)\n",
      "/content/new/21.jpg\n",
      "(245, 224, 3)\n",
      "(245, 224)\n",
      "(1, 241, 192)\n",
      "/content/new/22.jpg\n",
      "(325, 254, 3)\n",
      "(325, 254)\n",
      "(1, 315, 251)\n",
      "/content/new/23.jpg\n",
      "(300, 289)\n",
      "(300, 289)\n",
      "(1, 299, 255)\n",
      "/content/new/24.jpg\n",
      "(355, 311, 3)\n",
      "(355, 311)\n",
      "(1, 340, 299)\n",
      "/content/new/25.jpg\n",
      "(352, 321, 3)\n",
      "(352, 321)\n",
      "(1, 351, 316)\n",
      "/content/new/26.jpg\n",
      "(283, 231, 3)\n",
      "(283, 231)\n",
      "(1, 282, 230)\n",
      "/content/new/27.jpg\n",
      "(380, 310, 3)\n",
      "(380, 310)\n",
      "(1, 370, 305)\n",
      "/content/new/28.jpg\n",
      "(359, 300, 3)\n",
      "(359, 300)\n",
      "(1, 338, 246)\n",
      "/content/new/29.jpg\n",
      "(431, 400, 3)\n",
      "(431, 400)\n",
      "(1, 430, 399)\n",
      "/content/new/30.jpg\n",
      "(355, 310, 3)\n",
      "(355, 310)\n",
      "(1, 341, 288)\n",
      "/content/new/31.jpg\n",
      "(370, 286, 3)\n",
      "(370, 286)\n",
      "(1, 327, 258)\n",
      "/content/new/32.jpg\n",
      "(309, 232, 3)\n",
      "(309, 232)\n",
      "(1, 286, 220)\n",
      "/content/new/33.jpg\n",
      "(334, 283, 3)\n",
      "(334, 283)\n",
      "(1, 326, 267)\n",
      "/content/new/34.jpg\n",
      "(354, 303, 3)\n",
      "(354, 303)\n",
      "(1, 338, 280)\n",
      "/content/new/35.jpg\n",
      "(360, 313, 3)\n",
      "(360, 313)\n",
      "(1, 319, 269)\n",
      "/content/new/36.jpg\n",
      "(348, 297, 3)\n",
      "(348, 297)\n",
      "(1, 268, 220)\n",
      "/content/new/37.jpg\n",
      "(351, 273, 3)\n",
      "(351, 273)\n",
      "(1, 282, 225)\n",
      "/content/new/38.jpg\n",
      "(1200, 1059, 3)\n",
      "(1200, 1059)\n",
      "(1, 1054, 812)\n",
      "/content/new/39.jpg\n",
      "(316, 270, 3)\n",
      "(316, 270)\n",
      "(1, 277, 213)\n",
      "/content/new/40.jpg\n",
      "(336, 264, 3)\n",
      "(336, 264)\n",
      "(1, 316, 248)\n",
      "/content/new/41.jpg\n",
      "(303, 223, 3)\n",
      "(303, 223)\n",
      "(1, 273, 208)\n",
      "/content/new/42.jpg\n",
      "(291, 253, 3)\n",
      "(291, 253)\n",
      "(1, 273, 236)\n",
      "/content/new/43.jpg\n",
      "(350, 272, 3)\n",
      "(350, 272)\n",
      "(1, 345, 266)\n",
      "/content/new/44.jpg\n",
      "(300, 263, 3)\n",
      "(300, 263)\n",
      "(1, 278, 215)\n",
      "/content/new/45.jpg\n",
      "(325, 254, 3)\n",
      "(325, 254)\n",
      "(1, 315, 251)\n",
      "/content/new/46.jpg\n",
      "(300, 289)\n",
      "(300, 289)\n",
      "(1, 299, 255)\n",
      "/content/new/47.jpg\n",
      "(355, 290, 3)\n",
      "(355, 290)\n",
      "(1, 346, 275)\n",
      "/content/new/48.jpg\n",
      "(354, 279, 3)\n",
      "(354, 279)\n",
      "(1, 292, 247)\n",
      "/content/new/49.jpg\n",
      "(586, 467, 3)\n",
      "(586, 467)\n",
      "(1, 585, 466)\n",
      "/content/new/50.jpg\n",
      "(380, 310, 3)\n",
      "(380, 310)\n",
      "(1, 370, 305)\n",
      "/content/new/51.jpg\n",
      "(318, 273, 3)\n",
      "(318, 273)\n",
      "(1, 299, 258)\n",
      "/content/new/52.jpg\n",
      "(347, 300, 3)\n",
      "(347, 300)\n",
      "(1, 343, 295)\n",
      "/content/new/53.jpg\n",
      "(173, 189, 3)\n",
      "(173, 189)\n",
      "(1, 167, 154)\n",
      "/content/new/54.jpg\n",
      "(380, 318, 3)\n",
      "(380, 318)\n",
      "(1, 379, 308)\n",
      "/content/new/55.jpg\n",
      "(450, 355, 3)\n",
      "(450, 355)\n",
      "(1, 419, 337)\n",
      "/content/new/56.jpg\n",
      "(244, 206, 3)\n",
      "(244, 206)\n",
      "(1, 216, 159)\n",
      "/content/new/57.jpg\n",
      "(879, 766, 3)\n",
      "(879, 766)\n",
      "(1, 782, 626)\n",
      "/content/new/58.jpg\n",
      "(359, 297, 3)\n",
      "(359, 297)\n",
      "(1, 281, 221)\n",
      "/content/new/59.jpg\n",
      "(342, 273, 3)\n",
      "(342, 273)\n",
      "(1, 291, 229)\n",
      "/content/new/60.jpg\n",
      "(351, 262, 3)\n",
      "(351, 262)\n",
      "(1, 333, 234)\n",
      "/content/new/61.jpg\n",
      "(256, 256, 3)\n",
      "(256, 256)\n",
      "(1, 201, 161)\n",
      "/content/new/62.jpg\n",
      "(340, 314, 3)\n",
      "(340, 314)\n",
      "(1, 330, 299)\n",
      "/content/new/63.jpg\n",
      "(212, 209, 3)\n",
      "(212, 209)\n",
      "(1, 175, 146)\n",
      "/content/new/64.jpg\n",
      "(300, 240, 3)\n",
      "(300, 240)\n",
      "(1, 249, 194)\n",
      "/content/new/65.jpg\n",
      "(247, 204, 3)\n",
      "(247, 204)\n",
      "(1, 212, 155)\n",
      "/content/new/66.jpg\n",
      "(380, 294, 3)\n",
      "(380, 294)\n",
      "(1, 322, 241)\n",
      "/content/new/67.jpg\n",
      "(277, 272, 3)\n",
      "(277, 272)\n",
      "(1, 242, 207)\n",
      "/content/new/68.jpg\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1, 963, 783)\n",
      "/content/new/69.jpg\n",
      "(344, 279, 3)\n",
      "(344, 279)\n",
      "(1, 309, 229)\n",
      "/content/new/70.jpg\n",
      "(331, 272, 3)\n",
      "(331, 272)\n",
      "(1, 305, 258)\n",
      "/content/new/71.jpg\n",
      "(351, 278, 3)\n",
      "(351, 278)\n",
      "(1, 228, 205)\n",
      "/content/new/72.jpg\n",
      "(237, 213, 3)\n",
      "(237, 213)\n",
      "(1, 189, 143)\n",
      "/content/new/73.jpg\n",
      "(355, 294, 3)\n",
      "(355, 294)\n",
      "(1, 287, 225)\n",
      "/content/new/74.jpg\n",
      "(338, 248, 3)\n",
      "(338, 248)\n",
      "(1, 282, 203)\n",
      "/content/new/75.jpg\n",
      "(315, 289, 3)\n",
      "(315, 289)\n",
      "(1, 230, 252)\n",
      "/content/new/76.jpg\n",
      "(331, 260, 3)\n",
      "(331, 260)\n",
      "(1, 290, 232)\n",
      "/content/new/77.jpg\n",
      "(630, 504, 3)\n",
      "(630, 504)\n",
      "(1, 579, 460)\n",
      "/content/new/78.jpg\n",
      "(236, 213, 3)\n",
      "(236, 213)\n",
      "(1, 222, 189)\n",
      "/content/new/79.jpg\n",
      "(349, 278, 3)\n",
      "(349, 278)\n",
      "(1, 253, 212)\n",
      "/content/new/80.jpg\n",
      "(256, 197, 3)\n",
      "(256, 197)\n",
      "(1, 195, 174)\n",
      "/content/new/81.jpg\n",
      "(338, 283, 3)\n",
      "(338, 283)\n",
      "(1, 274, 222)\n",
      "/content/new/82.jpg\n",
      "(251, 201, 3)\n",
      "(251, 201)\n",
      "(1, 246, 199)\n",
      "/content/new/83.jpg\n",
      "(295, 283, 3)\n",
      "(295, 283)\n",
      "(1, 281, 258)\n",
      "/content/new/84.jpg\n",
      "(352, 281, 3)\n",
      "(352, 281)\n",
      "(1, 295, 221)\n",
      "/content/new/85.jpg\n",
      "(960, 781, 3)\n",
      "(960, 781)\n",
      "(1, 928, 744)\n",
      "/content/new/86.jpg\n",
      "(349, 292, 3)\n",
      "(349, 292)\n",
      "(1, 312, 227)\n",
      "/content/new/87.jpg\n",
      "(324, 278, 3)\n",
      "(324, 278)\n",
      "(1, 161, 136)\n",
      "/content/new/88.jpg\n",
      "(630, 628, 3)\n",
      "(630, 628)\n",
      "(1, 590, 533)\n",
      "/content/new/89.jpg\n",
      "(630, 630, 3)\n",
      "(630, 630)\n",
      "(1, 603, 474)\n",
      "/content/new/90.jpg\n",
      "(630, 630, 3)\n",
      "(630, 630)\n",
      "(1, 500, 411)\n",
      "/content/new/91.jpg\n",
      "(630, 630, 3)\n",
      "(630, 630)\n",
      "(1, 433, 402)\n",
      "/content/new/92.jpg\n",
      "(519, 456, 3)\n",
      "(519, 456)\n",
      "(1, 433, 380)\n",
      "/content/new/93.jpg\n",
      "(325, 300)\n",
      "(325, 300)\n",
      "(1, 313, 287)\n",
      "/content/new/94.jpg\n",
      "(294, 250)\n",
      "(294, 250)\n",
      "(1, 251, 214)\n",
      "/content/new/95.jpg\n",
      "(555, 526, 3)\n",
      "(555, 526)\n",
      "(1, 521, 487)\n",
      "/content/new/96.jpg\n",
      "(512, 512, 3)\n",
      "(512, 512)\n",
      "(1, 417, 352)\n",
      "/content/new/97.jpg\n",
      "(380, 310, 3)\n",
      "(380, 310)\n",
      "(1, 370, 305)\n",
      "/content/new/98.jpg\n",
      "(446, 450, 3)\n",
      "(446, 450)\n",
      "(1, 393, 305)\n",
      "/content/new/99.jpg\n",
      "(251, 204, 3)\n",
      "(251, 204)\n",
      "(1, 229, 184)\n",
      "/content/new/100.jpg\n",
      "(360, 319)\n",
      "(360, 319)\n",
      "(1, 359, 318)\n",
      "/content/new/101.jpg\n",
      "(325, 300)\n",
      "(325, 300)\n",
      "(1, 313, 287)\n",
      "/content/new/102.jpg\n",
      "(278, 236)\n",
      "(278, 236)\n",
      "(1, 270, 221)\n",
      "/content/new/103.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 179, 154)\n",
      "/content/new/104.jpg\n",
      "(365, 306, 3)\n",
      "(365, 306)\n",
      "(1, 354, 285)\n",
      "/content/new/105.jpg\n",
      "(1427, 1275)\n",
      "(1427, 1275)\n",
      "(1, 1364, 1136)\n",
      "/content/new/106.jpg\n",
      "(210, 200, 3)\n",
      "(210, 200)\n",
      "(1, 198, 174)\n",
      "/content/new/107.jpg\n",
      "(337, 293, 3)\n",
      "(337, 293)\n",
      "(1, 303, 254)\n",
      "/content/new/108.jpg\n",
      "(340, 291, 3)\n",
      "(340, 291)\n",
      "(1, 288, 227)\n",
      "/content/new/109.jpg\n",
      "(929, 634, 3)\n",
      "(929, 634)\n",
      "(1, 768, 584)\n",
      "/content/new/110.jpg\n",
      "(355, 320, 3)\n",
      "(355, 320)\n",
      "(1, 352, 319)\n",
      "/content/new/111.jpg\n",
      "(307, 271, 3)\n",
      "(307, 271)\n",
      "(1, 277, 213)\n",
      "/content/new/112.jpg\n",
      "(350, 315, 3)\n",
      "(350, 315)\n",
      "(1, 268, 220)\n",
      "/content/new/113.jpg\n",
      "(938, 911, 3)\n",
      "(938, 911)\n",
      "(1, 925, 846)\n",
      "/content/new/114.jpg\n",
      "(938, 911)\n",
      "(938, 911)\n",
      "(1, 889, 723)\n",
      "/content/new/115.jpg\n",
      "(219, 230, 3)\n",
      "(219, 230)\n",
      "(1, 202, 174)\n",
      "/content/new/116.jpg\n",
      "(325, 300)\n",
      "(325, 300)\n",
      "(1, 313, 287)\n",
      "/content/new/117.jpg\n",
      "(620, 620, 3)\n",
      "(620, 620)\n",
      "(1, 599, 505)\n",
      "/content/new/118.jpg\n",
      "(239, 211, 3)\n",
      "(239, 211)\n",
      "(1, 226, 175)\n",
      "/content/new/119.jpg\n",
      "(340, 314, 3)\n",
      "(340, 314)\n",
      "(1, 281, 248)\n",
      "/content/new/120.jpg\n",
      "(270, 229, 3)\n",
      "(270, 229)\n",
      "(1, 257, 212)\n",
      "/content/new/121.jpg\n",
      "(938, 911, 3)\n",
      "(938, 911)\n",
      "(1, 888, 723)\n",
      "/content/new/122.jpg\n",
      "(255, 197, 3)\n",
      "(255, 197)\n",
      "(1, 217, 154)\n",
      "/content/new/123.jpg\n",
      "(520, 433, 3)\n",
      "(520, 433)\n",
      "(1, 422, 337)\n",
      "/content/new/124.jpg\n",
      "(294, 250)\n",
      "(294, 250)\n",
      "(1, 251, 214)\n",
      "/content/new/125.jpg\n",
      "(243, 205, 3)\n",
      "(243, 205)\n",
      "(1, 229, 184)\n",
      "/content/new/126.jpg\n",
      "(340, 288, 3)\n",
      "(340, 288)\n",
      "(1, 262, 210)\n",
      "/content/new/127.jpg\n",
      "(233, 215, 3)\n",
      "(233, 215)\n",
      "(1, 181, 156)\n",
      "/content/new/128.jpg\n",
      "(630, 504, 3)\n",
      "(630, 504)\n",
      "(1, 579, 460)\n",
      "/content/new/129.jpg\n",
      "(456, 374, 3)\n",
      "(456, 374)\n",
      "(1, 391, 309)\n",
      "/content/new/130.jpg\n",
      "(325, 300)\n",
      "(325, 300)\n",
      "(1, 313, 287)\n",
      "/content/new/131.jpg\n",
      "(349, 300, 3)\n",
      "(349, 300)\n",
      "(1, 282, 226)\n",
      "/content/new/132.jpg\n",
      "(290, 250, 3)\n",
      "(290, 250)\n",
      "(1, 272, 229)\n",
      "/content/new/133.jpg\n",
      "(620, 620, 3)\n",
      "(620, 620)\n",
      "(1, 599, 505)\n",
      "/content/new/134.jpg\n",
      "(338, 264, 3)\n",
      "(338, 264)\n",
      "(1, 324, 261)\n",
      "/content/new/135.jpg\n",
      "(442, 353, 3)\n",
      "(442, 353)\n",
      "(1, 406, 322)\n",
      "/content/new/136.jpg\n",
      "(353, 300, 3)\n",
      "(353, 300)\n",
      "(1, 322, 257)\n",
      "/content/new/137.jpg\n",
      "(251, 201, 3)\n",
      "(251, 201)\n",
      "(1, 219, 176)\n",
      "/content/new/138.jpg\n",
      "(431, 400, 3)\n",
      "(431, 400)\n",
      "(1, 430, 399)\n",
      "/content/new/139.jpg\n",
      "(446, 450, 3)\n",
      "(446, 450)\n",
      "(1, 393, 305)\n",
      "/content/new/140.jpg\n",
      "(234, 216, 3)\n",
      "(234, 216)\n",
      "(1, 222, 193)\n",
      "/content/new/141.jpg\n",
      "(223, 226, 3)\n",
      "(223, 226)\n",
      "(1, 222, 225)\n",
      "/content/new/142.jpg\n",
      "(308, 244, 3)\n",
      "(308, 244)\n",
      "(1, 307, 239)\n",
      "/content/new/143.jpg\n",
      "(350, 272, 3)\n",
      "(350, 272)\n",
      "(1, 290, 231)\n",
      "/content/new/144.jpg\n",
      "(286, 241, 3)\n",
      "(286, 241)\n",
      "(1, 285, 240)\n",
      "/content/new/145.jpg\n",
      "(630, 630, 3)\n",
      "(630, 630)\n",
      "(1, 552, 464)\n",
      "/content/new/146.jpg\n",
      "(512, 512, 3)\n",
      "(512, 512)\n",
      "(1, 414, 372)\n",
      "/content/new/147.jpg\n",
      "(1280, 1061, 3)\n",
      "(1280, 1061)\n",
      "(1, 1228, 954)\n",
      "/content/new/148.jpg\n",
      "(260, 194, 3)\n",
      "(260, 194)\n",
      "(1, 215, 159)\n",
      "/content/new/149.jpg\n",
      "(300, 240)\n",
      "(300, 240)\n",
      "(1, 249, 194)\n",
      "/content/new/150.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 156, 151)\n",
      "/content/new/151.jpg\n",
      "(938, 864, 3)\n",
      "(938, 864)\n",
      "(1, 876, 707)\n",
      "/content/new/152.jpg\n",
      "(355, 272, 3)\n",
      "(355, 272)\n",
      "(1, 354, 271)\n",
      "/content/new/153.jpg\n",
      "(323, 276, 3)\n",
      "(323, 276)\n",
      "(1, 290, 249)\n",
      "/content/new/154.jpg\n",
      "(357, 283, 3)\n",
      "(357, 283)\n",
      "(1, 313, 255)\n",
      "98\n",
      "/content/no/1 no.jpeg\n",
      "(630, 630)\n",
      "(630, 630)\n",
      "(1, 523, 447)\n",
      "/content/no/10 no.jpg\n",
      "(201, 173, 3)\n",
      "(201, 173)\n",
      "(1, 157, 136)\n",
      "/content/no/11 no.jpg\n",
      "(168, 300, 3)\n",
      "(168, 300)\n",
      "(1, 126, 95)\n",
      "/content/no/12 no.jpg\n",
      "(183, 275, 3)\n",
      "(183, 275)\n",
      "(1, 165, 138)\n",
      "/content/no/13 no.jpg\n",
      "(168, 300, 3)\n",
      "(168, 300)\n",
      "(1, 140, 119)\n",
      "/content/no/14 no.jpg\n",
      "(197, 177, 3)\n",
      "(197, 177)\n",
      "(1, 144, 136)\n",
      "/content/no/15 no.jpg\n",
      "(217, 232, 3)\n",
      "(217, 232)\n",
      "(1, 215, 196)\n",
      "/content/no/17 no.jpg\n",
      "(231, 218, 3)\n",
      "(231, 218)\n",
      "(1, 180, 166)\n",
      "/content/no/18 no.jpg\n",
      "(221, 228, 3)\n",
      "(221, 228)\n",
      "(1, 181, 160)\n",
      "/content/no/19 no.jpg\n",
      "(200, 200, 3)\n",
      "(200, 200)\n",
      "(1, 120, 142)\n",
      "/content/no/2 no.jpeg\n",
      "(630, 630, 3)\n",
      "(630, 630)\n",
      "(1, 533, 438)\n",
      "/content/no/20 no.jpg\n",
      "(259, 194, 3)\n",
      "(259, 194)\n",
      "(1, 228, 165)\n",
      "/content/no/21 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 176, 131)\n",
      "/content/no/22 no.jpg\n",
      "(243, 207, 3)\n",
      "(243, 207)\n",
      "(1, 223, 179)\n",
      "/content/no/23 no.jpg\n",
      "(242, 208, 3)\n",
      "(242, 208)\n",
      "(1, 241, 207)\n",
      "/content/no/24 no.jpg\n",
      "(214, 235, 3)\n",
      "(214, 235)\n",
      "(1, 202, 195)\n",
      "/content/no/25 no.jpg\n",
      "(217, 232, 3)\n",
      "(217, 232)\n",
      "(1, 195, 167)\n",
      "/content/no/26 no.jpg\n",
      "(252, 200, 3)\n",
      "(252, 200)\n",
      "(1, 220, 174)\n",
      "/content/no/27 no.jpg\n",
      "(231, 218, 3)\n",
      "(231, 218)\n",
      "(1, 180, 166)\n",
      "/content/no/28 no.jpg\n",
      "(251, 201, 3)\n",
      "(251, 201)\n",
      "(1, 234, 196)\n",
      "/content/no/29 no.jpg\n",
      "(234, 215, 3)\n",
      "(234, 215)\n",
      "(1, 197, 167)\n",
      "/content/no/3 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 184, 144)\n",
      "/content/no/30 no.jpg\n",
      "(242, 208, 3)\n",
      "(242, 208)\n",
      "(1, 241, 207)\n",
      "/content/no/31 no.jpg\n",
      "(252, 200, 3)\n",
      "(252, 200)\n",
      "(1, 208, 157)\n",
      "/content/no/32 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 148, 113)\n",
      "/content/no/33 no.jpg\n",
      "(213, 236, 3)\n",
      "(213, 236)\n",
      "(1, 174, 133)\n",
      "/content/no/34 no.jpg\n",
      "(198, 150, 3)\n",
      "(198, 150)\n",
      "(1, 153, 121)\n",
      "/content/no/35 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 173, 135)\n",
      "/content/no/36 no.jpg\n",
      "(221, 228, 3)\n",
      "(221, 228)\n",
      "(1, 186, 142)\n",
      "/content/no/37 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 149, 122)\n",
      "/content/no/38 no.jpg\n",
      "(251, 201, 3)\n",
      "(251, 201)\n",
      "(1, 216, 159)\n",
      "/content/no/39 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 182, 133)\n",
      "/content/no/4 no.jpg\n",
      "(250, 201, 3)\n",
      "(250, 201)\n",
      "(1, 222, 174)\n",
      "/content/no/40 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 194, 154)\n",
      "/content/no/41 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 194, 154)\n",
      "/content/no/42 no.jpg\n",
      "(168, 300, 3)\n",
      "(168, 300)\n",
      "(1, 140, 119)\n",
      "/content/no/43 no.jpg\n",
      "(194, 259, 3)\n",
      "(194, 259)\n",
      "(1, 147, 121)\n",
      "/content/no/44no.jpg\n",
      "(442, 441, 3)\n",
      "(442, 441)\n",
      "(1, 408, 323)\n",
      "/content/no/45 no.jpg\n",
      "(474, 356, 3)\n",
      "(474, 356)\n",
      "(1, 365, 319)\n",
      "/content/no/46 no.jpg\n",
      "(530, 380, 3)\n",
      "(530, 380)\n",
      "(1, 384, 293)\n",
      "/content/no/47 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 181, 154)\n",
      "/content/no/48 no.jpeg\n",
      "(630, 630)\n",
      "(630, 630)\n",
      "(1, 491, 418)\n",
      "/content/no/49 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 165, 140)\n",
      "/content/no/5 no.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 157, 139)\n",
      "/content/no/50 no.jpg\n",
      "(222, 227, 3)\n",
      "(222, 227)\n",
      "(1, 192, 172)\n",
      "/content/no/6 no.jpg\n",
      "(192, 192, 3)\n",
      "(192, 192)\n",
      "(1, 142, 105)\n",
      "/content/no/7 no.jpg\n",
      "(417, 428, 3)\n",
      "(417, 428)\n",
      "(1, 336, 293)\n",
      "/content/no/8 no.jpg\n",
      "(251, 201, 3)\n",
      "(251, 201)\n",
      "(1, 216, 159)\n",
      "/content/no/9 no.jpg\n",
      "(201, 173, 3)\n",
      "(201, 173)\n",
      "(1, 157, 136)\n",
      "/content/no/N1.JPG\n",
      "(338, 276, 3)\n",
      "(338, 276)\n",
      "(1, 313, 240)\n",
      "/content/no/N11.jpg\n",
      "(614, 630, 3)\n",
      "(614, 630)\n",
      "(1, 590, 506)\n",
      "/content/no/N15.jpg\n",
      "(225, 225)\n",
      "(225, 225)\n",
      "(1, 202, 162)\n",
      "/content/no/N16.jpg\n",
      "(238, 212, 3)\n",
      "(238, 212)\n",
      "(1, 192, 176)\n",
      "/content/no/N17.jpg\n",
      "(393, 350, 3)\n",
      "(393, 350)\n",
      "(1, 318, 292)\n",
      "/content/no/N19.JPG\n",
      "(282, 230, 3)\n",
      "(282, 230)\n",
      "(1, 225, 188)\n",
      "/content/no/N2.JPG\n",
      "(248, 208, 3)\n",
      "(248, 208)\n",
      "(1, 231, 193)\n",
      "/content/no/N20.JPG\n",
      "(262, 227, 3)\n",
      "(262, 227)\n",
      "(1, 233, 203)\n",
      "/content/no/N21.jpg\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1, 942, 737)\n",
      "/content/no/N22.JPG\n",
      "(326, 276, 3)\n",
      "(326, 276)\n",
      "(1, 127, 208)\n",
      "/content/no/N26.JPG\n",
      "(264, 210, 3)\n",
      "(264, 210)\n",
      "(1, 210, 175)\n",
      "/content/no/N3.jpg\n",
      "(275, 220)\n",
      "(275, 220)\n",
      "(1, 236, 175)\n",
      "/content/no/N5.jpg\n",
      "(250, 201, 3)\n",
      "(250, 201)\n",
      "(1, 222, 174)\n",
      "/content/no/N6.jpg\n",
      "(257, 196, 3)\n",
      "(257, 196)\n",
      "(1, 226, 166)\n",
      "/content/no/No11.jpg\n",
      "(630, 630, 3)\n",
      "(630, 630)\n",
      "(1, 559, 425)\n",
      "/content/no/No12.jpg\n",
      "(537, 472, 3)\n",
      "(537, 472)\n",
      "(1, 492, 408)\n",
      "/content/no/No13.jpg\n",
      "(442, 442)\n",
      "(442, 442)\n",
      "(1, 350, 277)\n",
      "/content/no/No14.jpg\n",
      "(340, 339, 3)\n",
      "(340, 339)\n",
      "(1, 237, 183)\n",
      "/content/no/No15.jpg\n",
      "(400, 393, 4)\n",
      "(400, 393)\n",
      "(1, 348, 252)\n",
      "/content/no/No16.jpg\n",
      "(200, 300, 3)\n",
      "(200, 300)\n",
      "(1, 162, 145)\n",
      "/content/no/No17.jpg\n",
      "(400, 393, 4)\n",
      "(400, 393)\n",
      "(1, 348, 252)\n",
      "/content/no/No18.jpg\n",
      "(454, 442, 4)\n",
      "(454, 442)\n",
      "(1, 371, 282)\n",
      "/content/no/No19.jpg\n",
      "(680, 680, 3)\n",
      "(680, 680)\n",
      "(1, 595, 455)\n",
      "/content/no/No20.jpg\n",
      "(444, 468, 3)\n",
      "(444, 468)\n",
      "(1, 367, 268)\n",
      "/content/no/No21.jpg\n",
      "(442, 442)\n",
      "(442, 442)\n",
      "(1, 371, 302)\n",
      "/content/no/No22.jpg\n",
      "(449, 359, 3)\n",
      "(449, 359)\n",
      "(1, 359, 286)\n",
      "/content/no/no 1.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 165, 140)\n",
      "/content/no/no 10.jpg\n",
      "(750, 750)\n",
      "(750, 750)\n",
      "(1, 520, 418)\n",
      "/content/no/no 100.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 158, 139)\n",
      "/content/no/no 2.jpg\n",
      "(217, 232, 3)\n",
      "(217, 232)\n",
      "(1, 134, 127)\n",
      "/content/no/no 3.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 176, 134)\n",
      "/content/no/no 4.jpg\n",
      "(275, 220)\n",
      "(275, 220)\n",
      "(1, 236, 175)\n",
      "/content/no/no 5.jpeg\n",
      "(442, 442)\n",
      "(442, 442)\n",
      "(1, 370, 315)\n",
      "/content/no/no 6.jpg\n",
      "(236, 214, 3)\n",
      "(236, 214)\n",
      "(1, 191, 167)\n",
      "/content/no/no 7.jpeg\n",
      "(630, 630, 3)\n",
      "(630, 630)\n",
      "(1, 559, 425)\n",
      "/content/no/no 8.jpg\n",
      "(361, 642, 3)\n",
      "(361, 642)\n",
      "(1, 360, 320)\n",
      "/content/no/no 89.jpg\n",
      "(540, 504, 3)\n",
      "(540, 504)\n",
      "(1, 430, 320)\n",
      "/content/no/no 9.png\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920)\n",
      "(1, 969, 793)\n",
      "/content/no/no 90.jpg\n",
      "(280, 420, 3)\n",
      "(280, 420)\n",
      "(1, 241, 206)\n",
      "/content/no/no 91.jpeg\n",
      "(442, 400, 3)\n",
      "(442, 400)\n",
      "(1, 316, 280)\n",
      "/content/no/no 92.jpg\n",
      "(244, 206, 3)\n",
      "(244, 206)\n",
      "(1, 198, 167)\n",
      "/content/no/no 923.jpg\n",
      "(225, 225, 3)\n",
      "(225, 225)\n",
      "(1, 184, 154)\n",
      "/content/no/no 94.jpg\n",
      "(630, 630)\n",
      "(630, 630)\n",
      "(1, 523, 447)\n",
      "/content/no/no 95.jpg\n",
      "(301, 275)\n",
      "(301, 275)\n",
      "(1, 229, 218)\n",
      "/content/no/no 96.jpg\n",
      "(664, 550, 4)\n",
      "(664, 550)\n",
      "(1, 551, 417)\n",
      "/content/no/no 97.jpg\n",
      "(442, 442, 3)\n",
      "(442, 442)\n",
      "(1, 368, 303)\n",
      "/content/no/no 98.jpg\n",
      "(725, 728, 4)\n",
      "(725, 728)\n",
      "(1, 610, 484)\n",
      "/content/no/no 99.jpg\n",
      "(442, 409)\n",
      "(442, 409)\n",
      "(1, 426, 327)\n",
      "/content/no/no.jpg\n",
      "(512, 512, 4)\n",
      "(512, 512)\n",
      "(1, 453, 350)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.image as image\n",
    "\n",
    "data_dir = \"/content/yes\"\n",
    "dest_dir = \"/content/new\"\n",
    "patients = sorted(os.listdir(data_dir))\n",
    "print(len(patients))\n",
    "number = 0\n",
    "for i, patient in enumerate(patients):\n",
    "    p_dir = os.path.join(data_dir, patient)\n",
    "    d_dir = os.path.join(dest_dir, str(number)+\".jpg\")\n",
    "    print(d_dir)\n",
    "    img=image.imread(p_dir,\".jpg\")\n",
    "    print(img.shape)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    # print(img.shape)\n",
    "    img = crop.crop_imgs(img)\n",
    "    print(img.shape)\n",
    "    image.imsave(d_dir,img[0],cmap='gray')\n",
    "    number += 1\n",
    "data_dir = \"/content/no\"\n",
    "patients = sorted(os.listdir(data_dir))\n",
    "print(len(patients))\n",
    "for i, patient in enumerate(patients):\n",
    "    p_dir = os.path.join(data_dir, patient)\n",
    "    d_dir = os.path.join(dest_dir, str(number)+\".jpg\")\n",
    "    print(p_dir)\n",
    "    img=image.imread(p_dir,\".jpg\")\n",
    "    print(img.shape)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    # print(img.shape)\n",
    "    img = crop.crop_imgs(img)\n",
    "    print(img.shape)\n",
    "    image.imsave(d_dir,img[0],cmap='gray')\n",
    "    number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8098,
     "status": "ok",
     "timestamp": 1593194736131,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "CV77rV6_fPHH"
   },
   "outputs": [],
   "source": [
    "from Dataset import toumorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6217,
     "status": "ok",
     "timestamp": 1593194736132,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "G0J11Vh2bSje"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.RandomRotation(degrees=45),\n",
    "                                transforms.Resize((64,64), interpolation=2),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "                                      \n",
    "                                      # transforms.RandomRotation(degrees=45, fill=(0,)),\n",
    "                                      # transforms.CenterCrop(128),\n",
    "                                      # transforms.ToTensor(),\n",
    "                                      # transforms.Normalize((0.5), (1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4359,
     "status": "ok",
     "timestamp": 1593194736133,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "23Z_Kg23e4MF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init \n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "from scipy.special import comb\n",
    "import os\n",
    "import matplotlib.image as image\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2557,
     "status": "ok",
     "timestamp": 1593194736133,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "6fuwyCCJXHhe",
    "outputId": "614d801c-b6dc-48b0-c9d8-19c8fcea3bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046, 0.0046],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "trainvalid_split = 0.95\n",
    "train_split = 0.9\n",
    "batch_size = 10\n",
    "\n",
    "dataset_dir = '/content/new/'\n",
    "\n",
    "dataset = toumorDataset(dataset_dir,transform= transform)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "trainvalid_size = int(np.floor(trainvalid_split * dataset_size))\n",
    "test_size = dataset_size - trainvalid_size\n",
    "\n",
    "trainvalid_set, test_set = torch.utils.data.random_split(dataset, [trainvalid_size, test_size])\n",
    "\n",
    "dataset_size = len(trainvalid_set)\n",
    "train_size = int(np.floor(train_split * dataset_size))\n",
    "valid_size = dataset_size - train_size\n",
    "\n",
    "train_set, valid_set = torch.utils.data.random_split(trainvalid_set, [train_size, valid_size])\n",
    "\n",
    "train_samples_weights = torch.from_numpy(np.true_divide(np.ones(len(train_set)),len(train_set)))\n",
    "print(train_samples_weights)\n",
    "train_sampler = WeightedRandomSampler(weights=train_samples_weights, num_samples=len(train_samples_weights), replacement=True)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, sampler=train_sampler),\n",
    "    'val': DataLoader(valid_set, batch_size=batch_size, )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1193,
     "status": "ok",
     "timestamp": 1593163046682,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "zv7ydmcXQds_"
   },
   "outputs": [],
   "source": [
    "s = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1149,
     "status": "ok",
     "timestamp": 1592941327045,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "0Y_6tYGf_v2J",
    "outputId": "ee885211-ffcc-4fea-b16a-b6624e0bda30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1689,
     "status": "ok",
     "timestamp": 1593194747027,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "bB24gORoFOBA"
   },
   "outputs": [],
   "source": [
    "import Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1415,
     "status": "ok",
     "timestamp": 1593193818193,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "m2oXhxvyqQr3"
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False)\n",
    "\n",
    "def conv5x5(in_planes, out_planes, stride=1, groups=1, dilation=2):\n",
    "    \"\"\"5x5 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=5, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False)\n",
    "\n",
    "def conv7x7(in_planes, out_planes, stride=1, groups=1, dilation=3):\n",
    "    \"\"\"7x7 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=7, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes ,batchNormalization, dropOut, stride=1, downsample=None, groups=1,\n",
    "                 dilation=1, norm_layer=None ,num=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.batchNormalization = batchNormalization\n",
    "        self.dropOut = dropOut\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        if num == 1:\n",
    "            self.conv1 = conv7x7(inplanes, planes, stride)\n",
    "            if self.batchNormalization == True:\n",
    "                self.bn1 = norm_layer(planes)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            if self.dropOut == True:\n",
    "                self.do = nn.Dropout(p=0.3, inplace=False)\n",
    "            self.conv2 = conv7x7(planes, planes)\n",
    "            if self.batchNormalization == True:\n",
    "                self.bn2 = norm_layer(planes)\n",
    "            self.downsample = downsample\n",
    "            self.stride = stride\n",
    "        elif num == 2:\n",
    "            self.conv1 = conv5x5(inplanes, planes, stride)\n",
    "            if self.batchNormalization == True:\n",
    "                self.bn1 = norm_layer(planes)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            if self.dropOut == True:\n",
    "                self.do = nn.Dropout(p=0.3, inplace=False)\n",
    "            self.conv2 = conv5x5(planes, planes)\n",
    "            if self.batchNormalization == True:\n",
    "                self.bn2 = norm_layer(planes)\n",
    "            self.downsample = downsample\n",
    "            self.stride = stride\n",
    "        elif num == 3:\n",
    "            self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "            if self.batchNormalization == True:\n",
    "                self.bn1 = norm_layer(planes)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            if self.dropOut == True:\n",
    "                self.do = nn.Dropout(p=0.3, inplace=False)\n",
    "            self.conv2 = conv3x3(planes, planes)\n",
    "            if self.batchNormalization == True:\n",
    "                self.bn2 = norm_layer(planes)\n",
    "            self.downsample = downsample\n",
    "            self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        if self.batchNormalization == True:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        if self.dropOut == True:\n",
    "            out = self.do(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.batchNormalization == True:\n",
    "            out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, batchNormalization, dropOut, num_classes=2, zero_init_residual=False,\n",
    "                 groups=1, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.batchNormalization = batchNormalization\n",
    "        self.dropOut = dropOut\n",
    "        self.inplanes = 8\n",
    "        self.dilation = 1\n",
    "\n",
    "        self.groups = groups\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        if self.batchNormalization == True:\n",
    "            self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        if self.dropOut == True:\n",
    "            self.do = nn.Dropout(p=0.3, inplace=False)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        downsample = nn.Sequential(\n",
    "            conv1x1(8, 16, 1),\n",
    "        )\n",
    "        self.layer1 = block(8, 16, batchNormalization, dropOut, 1, downsample, self.groups, norm_layer, num=1)\n",
    "        downsample1 = nn.Sequential(\n",
    "            conv1x1(16, 32, 2),\n",
    "        )\n",
    "        self.layer2 = block(16, 32, batchNormalization, dropOut, 2, downsample1, self.groups, norm_layer, num=2)\n",
    "        downsample3 = nn.Sequential(\n",
    "            conv1x1(32, 64, 2),\n",
    "        )\n",
    "        self.layer3 = block(32, 64, batchNormalization, dropOut, 2, downsample3, self.groups, norm_layer, num=3)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(nn.Linear(64, 2),\n",
    "                                nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        print(self.batchNormalization)\n",
    "        x = self.conv1(x)\n",
    "        # print(\"1\",x.shape)\n",
    "        if self.batchNormalization == True :\n",
    "            print(\"here\")\n",
    "            x = self.bn1(x)\n",
    "        # print(\"2\",x.shape)\n",
    "        x = self.relu(x)\n",
    "        if self.dropOut == True:\n",
    "            x = self.do(x)\n",
    "        # print(\"3\",x.shape)\n",
    "        x = self.maxpool(x)\n",
    "        # print(\"4\",x.shape)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        # print(\"5\",x.shape)\n",
    "        x = self.layer2(x)\n",
    "        # print(\"6\",x.shape)\n",
    "        x = self.layer3(x)\n",
    "        # print(\"7\",x.shape)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # print(\"8\",x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(\"9\",x.shape)\n",
    "        x = self.fc(x)\n",
    "        # print(\"10\",x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def resnet(batchNormalization, dropOut, **kwargs):\n",
    "    model = ResNet(BasicBlock, [1, 1, 1], batchNormalization, dropOut, **kwargs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1201,
     "status": "ok",
     "timestamp": 1593195459337,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "1Q83gbz9ZM9t"
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    # bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    # pred = torch.sigmoid(pred)\n",
    "    # dice = dice_loss(pred, target)\n",
    "    \n",
    "    # loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    # metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    # metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss() \n",
    "    output = loss(pred, target)\n",
    "    # print(output)\n",
    "    metrics['loss'] += output.data.cpu().numpy() * target.size(0)\n",
    "    # return loss\n",
    "    return output\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    # current_loss = 0.0\n",
    "    current_corrects = 0\n",
    "    total = 0\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    " \n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                \n",
    "                inputs = ((inputs.reshape(-1,3,64,64)).float()).to(device)\n",
    "                labels = (labels).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs.float())\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # print(\"preds\",preds)\n",
    "                    # print(\"labels\",labels)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                epoch_samples += inputs.size(0)\n",
    "                current_corrects += torch.sum(preds == labels.data)\n",
    "                total += len(labels)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "            epoch_acc = current_corrects.double() / total\n",
    "            print(\"epoch_acc\",epoch_acc)\n",
    "            if phase == 'train':\n",
    "                train_acc.append(epoch_acc)\n",
    "            elif phase == 'val':\n",
    "                val_acc.append(epoch_acc)\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "            \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,train_acc,val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98040,
     "status": "ok",
     "timestamp": 1593195557086,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "CKe1z01jZXXA",
    "outputId": "c64ad840-0b7d-449e-a973-08123bad107a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "<bound method Module.children of ResNet(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): BasicBlock(\n",
      "    (conv1): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer2): BasicBlock(\n",
      "    (conv1): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer3): BasicBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): LogSoftmax()\n",
      "  )\n",
      ")>\n",
      "Epoch 0/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.666419\n",
      "epoch_acc tensor(0.6389, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.715969\n",
      "epoch_acc tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 1/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.674956\n",
      "epoch_acc tensor(0.6316, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.701654\n",
      "epoch_acc tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 2/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.666168\n",
      "epoch_acc tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.706583\n",
      "epoch_acc tensor(0.6208, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 3/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.642267\n",
      "epoch_acc tensor(0.6335, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.712215\n",
      "epoch_acc tensor(0.6302, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 4/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.665352\n",
      "epoch_acc tensor(0.6301, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.704102\n",
      "epoch_acc tensor(0.6275, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 5/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.636312\n",
      "epoch_acc tensor(0.6356, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.752218\n",
      "epoch_acc tensor(0.6333, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 6/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.683309\n",
      "epoch_acc tensor(0.6280, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.704118\n",
      "epoch_acc tensor(0.6262, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 7/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.676463\n",
      "epoch_acc tensor(0.6224, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.703577\n",
      "epoch_acc tensor(0.6208, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 8/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.640754\n",
      "epoch_acc tensor(0.6269, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.745775\n",
      "epoch_acc tensor(0.6255, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 9/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.680240\n",
      "epoch_acc tensor(0.6229, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.705291\n",
      "epoch_acc tensor(0.6217, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 10/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.671244\n",
      "epoch_acc tensor(0.6204, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.705315\n",
      "epoch_acc tensor(0.6193, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 11/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.663535\n",
      "epoch_acc tensor(0.6215, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.707756\n",
      "epoch_acc tensor(0.6205, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 12/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.637679\n",
      "epoch_acc tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.725504\n",
      "epoch_acc tensor(0.6240, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 13/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.652201\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.720338\n",
      "epoch_acc tensor(0.6244, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 14/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.666134\n",
      "epoch_acc tensor(0.6239, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.711258\n",
      "epoch_acc tensor(0.6231, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 15/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.652771\n",
      "epoch_acc tensor(0.6245, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.713339\n",
      "epoch_acc tensor(0.6237, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 16/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.659094\n",
      "epoch_acc tensor(0.6248, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.713088\n",
      "epoch_acc tensor(0.6240, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 17/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.658533\n",
      "epoch_acc tensor(0.6245, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.711791\n",
      "epoch_acc tensor(0.6238, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 18/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.644571\n",
      "epoch_acc tensor(0.6257, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.723736\n",
      "epoch_acc tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 19/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.660129\n",
      "epoch_acc tensor(0.6254, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.714656\n",
      "epoch_acc tensor(0.6248, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 20/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.656390\n",
      "epoch_acc tensor(0.6254, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.713152\n",
      "epoch_acc tensor(0.6248, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 21/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.669962\n",
      "epoch_acc tensor(0.6240, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.711521\n",
      "epoch_acc tensor(0.6235, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 22/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.660495\n",
      "epoch_acc tensor(0.6235, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.715066\n",
      "epoch_acc tensor(0.6230, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 23/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.641508\n",
      "epoch_acc tensor(0.6245, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.726797\n",
      "epoch_acc tensor(0.6240, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 24/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.628805\n",
      "epoch_acc tensor(0.6258, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.727480\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 25/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.656038\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.711988\n",
      "epoch_acc tensor(0.6248, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 26/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.663893\n",
      "epoch_acc tensor(0.6244, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.712670\n",
      "epoch_acc tensor(0.6239, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 27/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.656815\n",
      "epoch_acc tensor(0.6246, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.710048\n",
      "epoch_acc tensor(0.6241, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 28/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.607698\n",
      "epoch_acc tensor(0.6264, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.970574\n",
      "epoch_acc tensor(0.6260, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 29/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.666668\n",
      "epoch_acc tensor(0.6271, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.731931\n",
      "epoch_acc tensor(0.6267, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 30/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.648082\n",
      "epoch_acc tensor(0.6273, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.715884\n",
      "epoch_acc tensor(0.6269, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 31/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.643920\n",
      "epoch_acc tensor(0.6279, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.721260\n",
      "epoch_acc tensor(0.6275, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 32/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.676952\n",
      "epoch_acc tensor(0.6268, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.710599\n",
      "epoch_acc tensor(0.6264, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 33/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.666744\n",
      "epoch_acc tensor(0.6261, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.711040\n",
      "epoch_acc tensor(0.6257, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 34/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.679171\n",
      "epoch_acc tensor(0.6246, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.711627\n",
      "epoch_acc tensor(0.6243, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 35/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.686999\n",
      "epoch_acc tensor(0.6228, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.710018\n",
      "epoch_acc tensor(0.6225, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 36/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.670647\n",
      "epoch_acc tensor(0.6221, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.710600\n",
      "epoch_acc tensor(0.6217, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 37/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.655685\n",
      "epoch_acc tensor(0.6223, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.711541\n",
      "epoch_acc tensor(0.6219, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 38/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.659443\n",
      "epoch_acc tensor(0.6221, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.715473\n",
      "epoch_acc tensor(0.6218, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 39/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.659878\n",
      "epoch_acc tensor(0.6220, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.719601\n",
      "epoch_acc tensor(0.6217, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 40/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.669686\n",
      "epoch_acc tensor(0.6215, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.713024\n",
      "epoch_acc tensor(0.6212, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 41/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.634709\n",
      "epoch_acc tensor(0.6226, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.721980\n",
      "epoch_acc tensor(0.6223, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 42/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.653785\n",
      "epoch_acc tensor(0.6228, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.719246\n",
      "epoch_acc tensor(0.6225, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 43/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.622929\n",
      "epoch_acc tensor(0.6240, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.733279\n",
      "epoch_acc tensor(0.6237, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 44/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.657107\n",
      "epoch_acc tensor(0.6240, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.721054\n",
      "epoch_acc tensor(0.6237, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 45/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.647709\n",
      "epoch_acc tensor(0.6243, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.725847\n",
      "epoch_acc tensor(0.6240, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 46/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.650152\n",
      "epoch_acc tensor(0.6244, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.722726\n",
      "epoch_acc tensor(0.6241, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 47/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.625457\n",
      "epoch_acc tensor(0.6252, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.741585\n",
      "epoch_acc tensor(0.6249, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 48/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.633250\n",
      "epoch_acc tensor(0.6257, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.744039\n",
      "epoch_acc tensor(0.6254, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 49/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.678032\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.720973\n",
      "epoch_acc tensor(0.6248, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 50/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.649939\n",
      "epoch_acc tensor(0.6252, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.725193\n",
      "epoch_acc tensor(0.6249, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 51/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.644629\n",
      "epoch_acc tensor(0.6256, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.722855\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 52/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.671307\n",
      "epoch_acc tensor(0.6249, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.721511\n",
      "epoch_acc tensor(0.6247, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 53/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.661591\n",
      "epoch_acc tensor(0.6246, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.718134\n",
      "epoch_acc tensor(0.6244, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 54/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.638276\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.722138\n",
      "epoch_acc tensor(0.6248, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 55/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.655793\n",
      "epoch_acc tensor(0.6249, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.726838\n",
      "epoch_acc tensor(0.6247, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 56/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.661863\n",
      "epoch_acc tensor(0.6245, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.721109\n",
      "epoch_acc tensor(0.6243, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 57/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.599830\n",
      "epoch_acc tensor(0.6254, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.824465\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 58/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.663052\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.715798\n",
      "epoch_acc tensor(0.6249, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 59/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.668092\n",
      "epoch_acc tensor(0.6247, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.714406\n",
      "epoch_acc tensor(0.6245, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 60/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.669203\n",
      "epoch_acc tensor(0.6242, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.713879\n",
      "epoch_acc tensor(0.6240, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 61/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.656832\n",
      "epoch_acc tensor(0.6241, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.720267\n",
      "epoch_acc tensor(0.6239, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 62/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.625900\n",
      "epoch_acc tensor(0.6248, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.755380\n",
      "epoch_acc tensor(0.6246, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 63/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.653264\n",
      "epoch_acc tensor(0.6247, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.714498\n",
      "epoch_acc tensor(0.6245, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 64/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.645701\n",
      "epoch_acc tensor(0.6249, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.719182\n",
      "epoch_acc tensor(0.6247, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 65/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.667152\n",
      "epoch_acc tensor(0.6244, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.714205\n",
      "epoch_acc tensor(0.6242, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 66/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.661116\n",
      "epoch_acc tensor(0.6243, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.719828\n",
      "epoch_acc tensor(0.6241, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 67/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.637171\n",
      "epoch_acc tensor(0.6244, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.739475\n",
      "epoch_acc tensor(0.6243, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 68/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.626428\n",
      "epoch_acc tensor(0.6248, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.728415\n",
      "epoch_acc tensor(0.6246, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 69/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.630526\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.719622\n",
      "epoch_acc tensor(0.6249, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 70/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.642877\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.718071\n",
      "epoch_acc tensor(0.6249, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 71/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.640827\n",
      "epoch_acc tensor(0.6252, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.714936\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 72/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.647783\n",
      "epoch_acc tensor(0.6252, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.707491\n",
      "epoch_acc tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 73/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.665591\n",
      "epoch_acc tensor(0.6246, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.656229\n",
      "epoch_acc tensor(0.6245, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 74/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.610453\n",
      "epoch_acc tensor(0.6254, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.770856\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 75/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.660065\n",
      "epoch_acc tensor(0.6252, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.716591\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 76/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.658850\n",
      "epoch_acc tensor(0.6249, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.717690\n",
      "epoch_acc tensor(0.6247, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 77/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.620710\n",
      "epoch_acc tensor(0.6254, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.753588\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 78/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.617661\n",
      "epoch_acc tensor(0.6258, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.723456\n",
      "epoch_acc tensor(0.6257, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 79/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.669934\n",
      "epoch_acc tensor(0.6247, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.701869\n",
      "epoch_acc tensor(0.6246, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 80/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.572473\n",
      "epoch_acc tensor(0.6256, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.859339\n",
      "epoch_acc tensor(0.6254, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 81/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.685964\n",
      "epoch_acc tensor(0.6255, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.710964\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 82/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.653236\n",
      "epoch_acc tensor(0.6255, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.714265\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 83/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.656679\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.715490\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 84/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.636151\n",
      "epoch_acc tensor(0.6255, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.727618\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 85/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.662110\n",
      "epoch_acc tensor(0.6252, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.722333\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 86/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.647497\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.725727\n",
      "epoch_acc tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 87/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.632215\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.738478\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 88/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.635545\n",
      "epoch_acc tensor(0.6254, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.692344\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 89/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.640043\n",
      "epoch_acc tensor(0.6253, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.722135\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 90/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.643707\n",
      "epoch_acc tensor(0.6252, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.701100\n",
      "epoch_acc tensor(0.6251, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 91/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.607522\n",
      "epoch_acc tensor(0.6259, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.713605\n",
      "epoch_acc tensor(0.6258, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 92/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.679058\n",
      "epoch_acc tensor(0.6254, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.697299\n",
      "epoch_acc tensor(0.6252, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 93/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.573291\n",
      "epoch_acc tensor(0.6260, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.764164\n",
      "epoch_acc tensor(0.6259, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 94/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.630667\n",
      "epoch_acc tensor(0.6262, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.695023\n",
      "epoch_acc tensor(0.6261, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 95/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.575069\n",
      "epoch_acc tensor(0.6268, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.758009\n",
      "epoch_acc tensor(0.6267, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 96/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.573898\n",
      "epoch_acc tensor(0.6272, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.725783\n",
      "epoch_acc tensor(0.6271, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 97/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.604616\n",
      "epoch_acc tensor(0.6274, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.646788\n",
      "epoch_acc tensor(0.6273, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 98/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.640970\n",
      "epoch_acc tensor(0.6277, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.661136\n",
      "epoch_acc tensor(0.6276, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 99/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.606222\n",
      "epoch_acc tensor(0.6282, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.694667\n",
      "epoch_acc tensor(0.6281, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Best val loss: 0.646788\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "model1 = Resnet.resnet(batchNormalization=False, dropOut= False).to(device)\n",
    "model1.float()\n",
    "print(model1.children)\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model1.parameters()), lr=1e-3)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer_ft, \"min\", factor=0.8, patience=10, verbose=True)      \n",
    "              \n",
    "model1,tain_acc1,val_acc1 = train_model(model1, optimizer_ft, lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 195200,
     "status": "ok",
     "timestamp": 1593195658172,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "m-bcwd3X0LAM",
    "outputId": "e48b4a10-6523-401a-c63c-063b20445d8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "<bound method Module.children of ResNet(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): BasicBlock(\n",
      "    (conv1): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer2): BasicBlock(\n",
      "    (conv1): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer3): BasicBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): LogSoftmax()\n",
      "  )\n",
      ")>\n",
      "Epoch 0/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.659496\n",
      "epoch_acc tensor(0.6389, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.083511\n",
      "epoch_acc tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 1/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.545740\n",
      "epoch_acc tensor(0.6798, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.833692\n",
      "epoch_acc tensor(0.6708, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 2/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.588269\n",
      "epoch_acc tensor(0.6796, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.972049\n",
      "epoch_acc tensor(0.6778, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 3/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.541679\n",
      "epoch_acc tensor(0.6902, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.908669\n",
      "epoch_acc tensor(0.6865, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 4/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.414717\n",
      "epoch_acc tensor(0.7049, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.457459\n",
      "epoch_acc tensor(0.7050, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 5/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.480769\n",
      "epoch_acc tensor(0.7154, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.671039\n",
      "epoch_acc tensor(0.7132, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 6/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.454583\n",
      "epoch_acc tensor(0.7271, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.486299\n",
      "epoch_acc tensor(0.7274, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 7/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.353201\n",
      "epoch_acc tensor(0.7410, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.333300\n",
      "epoch_acc tensor(0.7396, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 8/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.371218\n",
      "epoch_acc tensor(0.7486, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.531529\n",
      "epoch_acc tensor(0.7486, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 9/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.403872\n",
      "epoch_acc tensor(0.7546, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.495392\n",
      "epoch_acc tensor(0.7554, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 10/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.401116\n",
      "epoch_acc tensor(0.7622, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.990404\n",
      "epoch_acc tensor(0.7621, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 11/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.368691\n",
      "epoch_acc tensor(0.7679, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.555048\n",
      "epoch_acc tensor(0.7674, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 12/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.368720\n",
      "epoch_acc tensor(0.7726, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.676984\n",
      "epoch_acc tensor(0.7715, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 13/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.359557\n",
      "epoch_acc tensor(0.7758, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.705701\n",
      "epoch_acc tensor(0.7747, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 14/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.327395\n",
      "epoch_acc tensor(0.7796, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.521216\n",
      "epoch_acc tensor(0.7797, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 15/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.405862\n",
      "epoch_acc tensor(0.7833, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.706074\n",
      "epoch_acc tensor(0.7826, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 16/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.393178\n",
      "epoch_acc tensor(0.7845, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.396842\n",
      "epoch_acc tensor(0.7850, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 17/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.353403\n",
      "epoch_acc tensor(0.7896, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.488313\n",
      "epoch_acc tensor(0.7894, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 18/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.267605\n",
      "epoch_acc tensor(0.7952, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.634398\n",
      "epoch_acc tensor(0.7950, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 19/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.350210\n",
      "epoch_acc tensor(0.7971, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.713760\n",
      "epoch_acc tensor(0.7965, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 20/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.317692\n",
      "epoch_acc tensor(0.7998, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.605656\n",
      "epoch_acc tensor(0.7994, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 21/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.339274\n",
      "epoch_acc tensor(0.8023, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.549775\n",
      "epoch_acc tensor(0.8019, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 22/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.301472\n",
      "epoch_acc tensor(0.8049, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.388140\n",
      "epoch_acc tensor(0.8047, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 23/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.261343\n",
      "epoch_acc tensor(0.8084, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.454482\n",
      "epoch_acc tensor(0.8083, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 24/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.239742\n",
      "epoch_acc tensor(0.8119, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.593702\n",
      "epoch_acc tensor(0.8118, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 25/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.253495\n",
      "epoch_acc tensor(0.8145, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.504409\n",
      "epoch_acc tensor(0.8144, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 26/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.218097\n",
      "epoch_acc tensor(0.8177, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.480312\n",
      "epoch_acc tensor(0.8174, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 27/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.283875\n",
      "epoch_acc tensor(0.8191, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.400866\n",
      "epoch_acc tensor(0.8192, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 28/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.398289\n",
      "epoch_acc tensor(0.8193, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.788161\n",
      "epoch_acc tensor(0.8188, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 29/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.302922\n",
      "epoch_acc tensor(0.8205, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.457613\n",
      "epoch_acc tensor(0.8206, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 30/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.263578\n",
      "epoch_acc tensor(0.8231, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.560364\n",
      "epoch_acc tensor(0.8231, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 31/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.233633\n",
      "epoch_acc tensor(0.8256, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.457279\n",
      "epoch_acc tensor(0.8255, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 32/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.257371\n",
      "epoch_acc tensor(0.8280, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.427120\n",
      "epoch_acc tensor(0.8280, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 33/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.265844\n",
      "epoch_acc tensor(0.8296, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.511662\n",
      "epoch_acc tensor(0.8295, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 34/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.303213\n",
      "epoch_acc tensor(0.8309, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.287785\n",
      "epoch_acc tensor(0.8312, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 35/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.209644\n",
      "epoch_acc tensor(0.8337, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.400861\n",
      "epoch_acc tensor(0.8336, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 36/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.189553\n",
      "epoch_acc tensor(0.8359, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.412023\n",
      "epoch_acc tensor(0.8359, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 37/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.278031\n",
      "epoch_acc tensor(0.8370, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.655104\n",
      "epoch_acc tensor(0.8367, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 38/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.211470\n",
      "epoch_acc tensor(0.8384, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.563901\n",
      "epoch_acc tensor(0.8381, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 39/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.200813\n",
      "epoch_acc tensor(0.8398, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.782838\n",
      "epoch_acc tensor(0.8396, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 40/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.210211\n",
      "epoch_acc tensor(0.8412, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.380429\n",
      "epoch_acc tensor(0.8412, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 41/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.129204\n",
      "epoch_acc tensor(0.8437, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.753637\n",
      "epoch_acc tensor(0.8435, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 42/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.177097\n",
      "epoch_acc tensor(0.8453, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.539599\n",
      "epoch_acc tensor(0.8452, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 43/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.182245\n",
      "epoch_acc tensor(0.8471, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.454159\n",
      "epoch_acc tensor(0.8470, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 44/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.151185\n",
      "epoch_acc tensor(0.8489, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.444467\n",
      "epoch_acc tensor(0.8488, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 45/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.174221\n",
      "epoch_acc tensor(0.8505, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.508096\n",
      "epoch_acc tensor(0.8503, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 46/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.247264\n",
      "epoch_acc tensor(0.8511, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.276675\n",
      "epoch_acc tensor(0.8511, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 47/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.215112\n",
      "epoch_acc tensor(0.8520, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.513890\n",
      "epoch_acc tensor(0.8520, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 48/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.142353\n",
      "epoch_acc tensor(0.8540, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.564420\n",
      "epoch_acc tensor(0.8538, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 49/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.118121\n",
      "epoch_acc tensor(0.8558, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.529929\n",
      "epoch_acc tensor(0.8557, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 50/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.194081\n",
      "epoch_acc tensor(0.8572, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.228142\n",
      "epoch_acc tensor(0.8572, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 51/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.163923\n",
      "epoch_acc tensor(0.8585, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.426546\n",
      "epoch_acc tensor(0.8583, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 52/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.199962\n",
      "epoch_acc tensor(0.8591, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.460646\n",
      "epoch_acc tensor(0.8590, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 53/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.172732\n",
      "epoch_acc tensor(0.8602, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.554630\n",
      "epoch_acc tensor(0.8601, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 54/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.140327\n",
      "epoch_acc tensor(0.8616, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.616991\n",
      "epoch_acc tensor(0.8614, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 55/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.184009\n",
      "epoch_acc tensor(0.8626, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.447335\n",
      "epoch_acc tensor(0.8624, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 56/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.149534\n",
      "epoch_acc tensor(0.8639, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.419286\n",
      "epoch_acc tensor(0.8639, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 57/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.208417\n",
      "epoch_acc tensor(0.8645, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.618104\n",
      "epoch_acc tensor(0.8644, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 58/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.114102\n",
      "epoch_acc tensor(0.8657, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.504730\n",
      "epoch_acc tensor(0.8656, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 59/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.223757\n",
      "epoch_acc tensor(0.8664, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.385322\n",
      "epoch_acc tensor(0.8665, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 60/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.129297\n",
      "epoch_acc tensor(0.8677, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.395850\n",
      "epoch_acc tensor(0.8676, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 61/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.154255\n",
      "epoch_acc tensor(0.8685, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.380720\n",
      "epoch_acc tensor(0.8683, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 62/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.110175\n",
      "epoch_acc tensor(0.8697, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.903543\n",
      "epoch_acc tensor(0.8695, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 63/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.143170\n",
      "epoch_acc tensor(0.8705, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.440474\n",
      "epoch_acc tensor(0.8704, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 64/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.107494\n",
      "epoch_acc tensor(0.8716, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.405535\n",
      "epoch_acc tensor(0.8715, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 65/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.132606\n",
      "epoch_acc tensor(0.8724, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.010340\n",
      "epoch_acc tensor(0.8723, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 66/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.149736\n",
      "epoch_acc tensor(0.8733, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.244493\n",
      "epoch_acc tensor(0.8733, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 67/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.104614\n",
      "epoch_acc tensor(0.8744, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.718205\n",
      "epoch_acc tensor(0.8743, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 68/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.072397\n",
      "epoch_acc tensor(0.8756, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.395323\n",
      "epoch_acc tensor(0.8755, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 69/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.079640\n",
      "epoch_acc tensor(0.8769, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.436832\n",
      "epoch_acc tensor(0.8769, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 70/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.110942\n",
      "epoch_acc tensor(0.8779, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.484034\n",
      "epoch_acc tensor(0.8778, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 71/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.074279\n",
      "epoch_acc tensor(0.8789, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.432792\n",
      "epoch_acc tensor(0.8789, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 72/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.113908\n",
      "epoch_acc tensor(0.8798, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.553205\n",
      "epoch_acc tensor(0.8797, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 73/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.090276\n",
      "epoch_acc tensor(0.8806, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.437682\n",
      "epoch_acc tensor(0.8806, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 74/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.145946\n",
      "epoch_acc tensor(0.8816, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.595622\n",
      "epoch_acc tensor(0.8814, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 75/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.093442\n",
      "epoch_acc tensor(0.8825, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.520182\n",
      "epoch_acc tensor(0.8824, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 76/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.127463\n",
      "epoch_acc tensor(0.8831, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.332571\n",
      "epoch_acc tensor(0.8828, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 77/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.278721\n",
      "epoch_acc tensor(0.8830, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.404807\n",
      "epoch_acc tensor(0.8830, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 78/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.129897\n",
      "epoch_acc tensor(0.8836, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.183030\n",
      "epoch_acc tensor(0.8831, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 79/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.154413\n",
      "epoch_acc tensor(0.8838, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.544321\n",
      "epoch_acc tensor(0.8837, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 80/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.149100\n",
      "epoch_acc tensor(0.8845, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.562977\n",
      "epoch_acc tensor(0.8845, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 81/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.201848\n",
      "epoch_acc tensor(0.8846, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.106387\n",
      "epoch_acc tensor(0.8844, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 82/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.235713\n",
      "epoch_acc tensor(0.8847, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.814276\n",
      "epoch_acc tensor(0.8844, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 83/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.145063\n",
      "epoch_acc tensor(0.8849, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.578553\n",
      "epoch_acc tensor(0.8849, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 84/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.061621\n",
      "epoch_acc tensor(0.8860, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.711357\n",
      "epoch_acc tensor(0.8858, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 85/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.088166\n",
      "epoch_acc tensor(0.8866, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.387664\n",
      "epoch_acc tensor(0.8866, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 86/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.099501\n",
      "epoch_acc tensor(0.8873, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.489601\n",
      "epoch_acc tensor(0.8873, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 87/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.088449\n",
      "epoch_acc tensor(0.8882, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.277717\n",
      "epoch_acc tensor(0.8881, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 88/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.091979\n",
      "epoch_acc tensor(0.8889, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.471697\n",
      "epoch_acc tensor(0.8889, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 89/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.062103\n",
      "epoch_acc tensor(0.8899, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.748774\n",
      "epoch_acc tensor(0.8899, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 90/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.108510\n",
      "epoch_acc tensor(0.8905, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 3.229635\n",
      "epoch_acc tensor(0.8901, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 91/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.185422\n",
      "epoch_acc tensor(0.8905, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.640775\n",
      "epoch_acc tensor(0.8903, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 92/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.100551\n",
      "epoch_acc tensor(0.8910, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.929916\n",
      "epoch_acc tensor(0.8908, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 93/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.082650\n",
      "epoch_acc tensor(0.8915, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.626997\n",
      "epoch_acc tensor(0.8914, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 94/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.043759\n",
      "epoch_acc tensor(0.8922, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.698440\n",
      "epoch_acc tensor(0.8921, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 95/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.057887\n",
      "epoch_acc tensor(0.8929, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.257371\n",
      "epoch_acc tensor(0.8928, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 96/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.043213\n",
      "epoch_acc tensor(0.8937, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.242820\n",
      "epoch_acc tensor(0.8936, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 97/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.039421\n",
      "epoch_acc tensor(0.8945, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.521619\n",
      "epoch_acc tensor(0.8944, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 98/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.055148\n",
      "epoch_acc tensor(0.8952, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.338812\n",
      "epoch_acc tensor(0.8951, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 99/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.042195\n",
      "epoch_acc tensor(0.8959, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.280054\n",
      "epoch_acc tensor(0.8959, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Best val loss: 0.228142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#with batch normalization\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Resnet.resnet(batchNormalization=True, dropOut= False).to(device)\n",
    "model2.float()\n",
    "print(model2.children)\n",
    "\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model2.parameters()), lr=1e-3)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer_ft, \"min\", factor=0.8, patience=10, verbose=True)      \n",
    "              \n",
    "model2,tain_acc2,val_acc2 = train_model(model2, optimizer_ft, lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 289364,
     "status": "ok",
     "timestamp": 1593195753654,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "29TRYGsN3Ql3",
    "outputId": "aaedd424-e532-452e-8a8a-bce75dd7dc61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "<bound method Module.children of ResNet(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (do): Dropout(p=0.3, inplace=False)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): BasicBlock(\n",
      "    (conv1): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (do): Dropout(p=0.3, inplace=False)\n",
      "    (conv2): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer2): BasicBlock(\n",
      "    (conv1): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (do): Dropout(p=0.3, inplace=False)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer3): BasicBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (do): Dropout(p=0.3, inplace=False)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): LogSoftmax()\n",
      "  )\n",
      ")>\n",
      "Epoch 0/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.688576\n",
      "epoch_acc tensor(0.6019, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.685982\n",
      "epoch_acc tensor(0.5917, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 1/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.681628\n",
      "epoch_acc tensor(0.5680, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.695059\n",
      "epoch_acc tensor(0.5646, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 2/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.685561\n",
      "epoch_acc tensor(0.5747, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.689107\n",
      "epoch_acc tensor(0.5778, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 3/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.680647\n",
      "epoch_acc tensor(0.5865, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.687931\n",
      "epoch_acc tensor(0.5844, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 4/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.613170\n",
      "epoch_acc tensor(0.6071, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.691847\n",
      "epoch_acc tensor(0.6050, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 5/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.649419\n",
      "epoch_acc tensor(0.6130, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.684506\n",
      "epoch_acc tensor(0.6111, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 6/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.662545\n",
      "epoch_acc tensor(0.6129, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.683391\n",
      "epoch_acc tensor(0.6113, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 7/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.662582\n",
      "epoch_acc tensor(0.6134, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.682026\n",
      "epoch_acc tensor(0.6120, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 8/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.612917\n",
      "epoch_acc tensor(0.6213, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.689537\n",
      "epoch_acc tensor(0.6199, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 9/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.655416\n",
      "epoch_acc tensor(0.6221, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.692969\n",
      "epoch_acc tensor(0.6208, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 10/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.623410\n",
      "epoch_acc tensor(0.6273, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.712146\n",
      "epoch_acc tensor(0.6261, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 11/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.638655\n",
      "epoch_acc tensor(0.6296, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.697049\n",
      "epoch_acc tensor(0.6285, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 12/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.597903\n",
      "epoch_acc tensor(0.6337, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.709953\n",
      "epoch_acc tensor(0.6327, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 13/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.588636\n",
      "epoch_acc tensor(0.6370, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.689866\n",
      "epoch_acc tensor(0.6360, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 14/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.648545\n",
      "epoch_acc tensor(0.6367, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.682605\n",
      "epoch_acc tensor(0.6358, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 15/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.637561\n",
      "epoch_acc tensor(0.6368, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.687808\n",
      "epoch_acc tensor(0.6359, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 16/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.653590\n",
      "epoch_acc tensor(0.6354, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.685406\n",
      "epoch_acc tensor(0.6346, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 17/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.659065\n",
      "epoch_acc tensor(0.6341, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.677410\n",
      "epoch_acc tensor(0.6333, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 18/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.651684\n",
      "epoch_acc tensor(0.6327, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.680961\n",
      "epoch_acc tensor(0.6320, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 19/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.664792\n",
      "epoch_acc tensor(0.6307, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.682966\n",
      "epoch_acc tensor(0.6300, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 20/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.625119\n",
      "epoch_acc tensor(0.6314, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.727693\n",
      "epoch_acc tensor(0.6308, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 21/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.627910\n",
      "epoch_acc tensor(0.6318, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.681265\n",
      "epoch_acc tensor(0.6312, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 22/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.625657\n",
      "epoch_acc tensor(0.6321, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.678820\n",
      "epoch_acc tensor(0.6315, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 23/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.615955\n",
      "epoch_acc tensor(0.6327, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.684296\n",
      "epoch_acc tensor(0.6321, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 24/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.608004\n",
      "epoch_acc tensor(0.6337, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.676911\n",
      "epoch_acc tensor(0.6332, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 25/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.626961\n",
      "epoch_acc tensor(0.6348, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.691019\n",
      "epoch_acc tensor(0.6343, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 26/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.650171\n",
      "epoch_acc tensor(0.6334, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.678523\n",
      "epoch_acc tensor(0.6329, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 27/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.609296\n",
      "epoch_acc tensor(0.6347, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.747995\n",
      "epoch_acc tensor(0.6342, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 28/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.662147\n",
      "epoch_acc tensor(0.6341, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.675130\n",
      "epoch_acc tensor(0.6336, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 29/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.641789\n",
      "epoch_acc tensor(0.6336, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.685104\n",
      "epoch_acc tensor(0.6332, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 30/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.630446\n",
      "epoch_acc tensor(0.6331, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.672872\n",
      "epoch_acc tensor(0.6327, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 31/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.577408\n",
      "epoch_acc tensor(0.6345, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.656808\n",
      "epoch_acc tensor(0.6341, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 32/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.587647\n",
      "epoch_acc tensor(0.6353, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.745497\n",
      "epoch_acc tensor(0.6348, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 33/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.616293\n",
      "epoch_acc tensor(0.6350, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.668804\n",
      "epoch_acc tensor(0.6346, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 34/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.624255\n",
      "epoch_acc tensor(0.6349, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.657786\n",
      "epoch_acc tensor(0.6345, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 35/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.595614\n",
      "epoch_acc tensor(0.6347, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.652452\n",
      "epoch_acc tensor(0.6344, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 36/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.598064\n",
      "epoch_acc tensor(0.6340, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.653918\n",
      "epoch_acc tensor(0.6337, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 37/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.699793\n",
      "epoch_acc tensor(0.6323, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.677245\n",
      "epoch_acc tensor(0.6319, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 38/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.592378\n",
      "epoch_acc tensor(0.6324, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.650583\n",
      "epoch_acc tensor(0.6321, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 39/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.592484\n",
      "epoch_acc tensor(0.6335, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.686413\n",
      "epoch_acc tensor(0.6331, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 40/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.603163\n",
      "epoch_acc tensor(0.6339, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.662675\n",
      "epoch_acc tensor(0.6335, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 41/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.576414\n",
      "epoch_acc tensor(0.6345, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.674089\n",
      "epoch_acc tensor(0.6342, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 42/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.623583\n",
      "epoch_acc tensor(0.6345, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.669012\n",
      "epoch_acc tensor(0.6342, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 43/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.647062\n",
      "epoch_acc tensor(0.6335, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.664484\n",
      "epoch_acc tensor(0.6333, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 44/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.605882\n",
      "epoch_acc tensor(0.6338, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.669590\n",
      "epoch_acc tensor(0.6335, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 45/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.558450\n",
      "epoch_acc tensor(0.6344, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.633537\n",
      "epoch_acc tensor(0.6341, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 46/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.578626\n",
      "epoch_acc tensor(0.6345, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.672639\n",
      "epoch_acc tensor(0.6342, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 47/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.586587\n",
      "epoch_acc tensor(0.6353, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.665298\n",
      "epoch_acc tensor(0.6350, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 48/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.622544\n",
      "epoch_acc tensor(0.6352, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.658530\n",
      "epoch_acc tensor(0.6349, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 49/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.628200\n",
      "epoch_acc tensor(0.6346, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.647900\n",
      "epoch_acc tensor(0.6346, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 50/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.641058\n",
      "epoch_acc tensor(0.6347, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.655584\n",
      "epoch_acc tensor(0.6344, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 51/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.603247\n",
      "epoch_acc tensor(0.6341, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.656065\n",
      "epoch_acc tensor(0.6338, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 52/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.580452\n",
      "epoch_acc tensor(0.6340, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.664485\n",
      "epoch_acc tensor(0.6338, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 53/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.593045\n",
      "epoch_acc tensor(0.6346, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.628183\n",
      "epoch_acc tensor(0.6346, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 54/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.593896\n",
      "epoch_acc tensor(0.6348, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.626267\n",
      "epoch_acc tensor(0.6348, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 55/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.607428\n",
      "epoch_acc tensor(0.6353, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.635525\n",
      "epoch_acc tensor(0.6350, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 56/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.560550\n",
      "epoch_acc tensor(0.6362, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.685444\n",
      "epoch_acc tensor(0.6360, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 57/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.606475\n",
      "epoch_acc tensor(0.6362, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.663801\n",
      "epoch_acc tensor(0.6360, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 58/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.573567\n",
      "epoch_acc tensor(0.6362, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.653287\n",
      "epoch_acc tensor(0.6359, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 59/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.627667\n",
      "epoch_acc tensor(0.6352, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.629103\n",
      "epoch_acc tensor(0.6351, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 60/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.591904\n",
      "epoch_acc tensor(0.6352, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.668570\n",
      "epoch_acc tensor(0.6350, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 61/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.597542\n",
      "epoch_acc tensor(0.6351, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.636889\n",
      "epoch_acc tensor(0.6349, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 62/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.642084\n",
      "epoch_acc tensor(0.6349, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.629727\n",
      "epoch_acc tensor(0.6347, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 63/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.622087\n",
      "epoch_acc tensor(0.6347, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.649224\n",
      "epoch_acc tensor(0.6344, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 64/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.601800\n",
      "epoch_acc tensor(0.6342, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.643003\n",
      "epoch_acc tensor(0.6342, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 65/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.585703\n",
      "epoch_acc tensor(0.6345, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.644794\n",
      "epoch_acc tensor(0.6347, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 66/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.555541\n",
      "epoch_acc tensor(0.6355, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.605156\n",
      "epoch_acc tensor(0.6357, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 67/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.644124\n",
      "epoch_acc tensor(0.6358, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.620499\n",
      "epoch_acc tensor(0.6358, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 68/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.553400\n",
      "epoch_acc tensor(0.6366, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.613532\n",
      "epoch_acc tensor(0.6367, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 69/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.576468\n",
      "epoch_acc tensor(0.6375, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.630950\n",
      "epoch_acc tensor(0.6375, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 70/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.615355\n",
      "epoch_acc tensor(0.6368, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.650922\n",
      "epoch_acc tensor(0.6368, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 71/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.531137\n",
      "epoch_acc tensor(0.6374, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.677424\n",
      "epoch_acc tensor(0.6372, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 72/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.623858\n",
      "epoch_acc tensor(0.6375, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.649448\n",
      "epoch_acc tensor(0.6376, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 73/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.586249\n",
      "epoch_acc tensor(0.6384, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.624526\n",
      "epoch_acc tensor(0.6382, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 74/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.572669\n",
      "epoch_acc tensor(0.6394, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.640184\n",
      "epoch_acc tensor(0.6392, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 75/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.590417\n",
      "epoch_acc tensor(0.6387, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.577721\n",
      "epoch_acc tensor(0.6388, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 76/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.543859\n",
      "epoch_acc tensor(0.6398, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.655990\n",
      "epoch_acc tensor(0.6398, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 77/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.620269\n",
      "epoch_acc tensor(0.6402, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.643176\n",
      "epoch_acc tensor(0.6401, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 78/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.591967\n",
      "epoch_acc tensor(0.6403, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.614925\n",
      "epoch_acc tensor(0.6402, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 79/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.581209\n",
      "epoch_acc tensor(0.6410, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.650040\n",
      "epoch_acc tensor(0.6409, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 80/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.593800\n",
      "epoch_acc tensor(0.6419, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.612490\n",
      "epoch_acc tensor(0.6420, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 81/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.626442\n",
      "epoch_acc tensor(0.6422, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.634291\n",
      "epoch_acc tensor(0.6422, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 82/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.524843\n",
      "epoch_acc tensor(0.6434, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.549311\n",
      "epoch_acc tensor(0.6435, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 83/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.543923\n",
      "epoch_acc tensor(0.6446, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.637041\n",
      "epoch_acc tensor(0.6446, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 84/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.617469\n",
      "epoch_acc tensor(0.6443, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.597270\n",
      "epoch_acc tensor(0.6443, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 85/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.572997\n",
      "epoch_acc tensor(0.6446, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.624193\n",
      "epoch_acc tensor(0.6446, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 86/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.547993\n",
      "epoch_acc tensor(0.6455, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.606209\n",
      "epoch_acc tensor(0.6455, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 87/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.588730\n",
      "epoch_acc tensor(0.6463, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.612583\n",
      "epoch_acc tensor(0.6462, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 88/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.562185\n",
      "epoch_acc tensor(0.6466, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.533446\n",
      "epoch_acc tensor(0.6467, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 89/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.564702\n",
      "epoch_acc tensor(0.6478, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.577893\n",
      "epoch_acc tensor(0.6479, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 90/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.515332\n",
      "epoch_acc tensor(0.6492, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.479090\n",
      "epoch_acc tensor(0.6495, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 91/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.564392\n",
      "epoch_acc tensor(0.6503, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.602155\n",
      "epoch_acc tensor(0.6502, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 92/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.492347\n",
      "epoch_acc tensor(0.6515, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.596963\n",
      "epoch_acc tensor(0.6516, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 93/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.467079\n",
      "epoch_acc tensor(0.6529, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.464322\n",
      "epoch_acc tensor(0.6531, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 94/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.495727\n",
      "epoch_acc tensor(0.6539, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.487526\n",
      "epoch_acc tensor(0.6541, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 95/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.441378\n",
      "epoch_acc tensor(0.6554, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.592830\n",
      "epoch_acc tensor(0.6555, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 96/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.605440\n",
      "epoch_acc tensor(0.6558, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.588594\n",
      "epoch_acc tensor(0.6560, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 97/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.472450\n",
      "epoch_acc tensor(0.6566, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.525173\n",
      "epoch_acc tensor(0.6568, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 98/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.461620\n",
      "epoch_acc tensor(0.6582, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.529783\n",
      "epoch_acc tensor(0.6582, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 99/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.500830\n",
      "epoch_acc tensor(0.6591, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.612741\n",
      "epoch_acc tensor(0.6591, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Best val loss: 0.464322\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#wiith drop out\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 1\n",
    "\n",
    "model3 = Resnet.resnet(batchNormalization=False, dropOut= True).to(device)\n",
    "model3.float()\n",
    "print(model3.children)\n",
    "\n",
    "\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model3.parameters()), lr=1e-3)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer_ft, \"min\", factor=0.8, patience=10, verbose=True)      \n",
    "              \n",
    "model3,tain_acc3,val_acc3 = train_model(model3, optimizer_ft, lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 386904,
     "status": "ok",
     "timestamp": 1593195855294,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "f9Iop-Ur67Wa",
    "outputId": "a3332069-3891-4389-a6ce-f04fb42d5843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "<bound method Module.children of ResNet(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (do): Dropout(p=0.3, inplace=False)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): BasicBlock(\n",
      "    (conv1): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (do): Dropout(p=0.3, inplace=False)\n",
      "    (conv2): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer2): BasicBlock(\n",
      "    (conv1): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (do): Dropout(p=0.3, inplace=False)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer3): BasicBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (do): Dropout(p=0.3, inplace=False)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): LogSoftmax()\n",
      "  )\n",
      ")>\n",
      "Epoch 0/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.664292\n",
      "epoch_acc tensor(0.6111, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.001980\n",
      "epoch_acc tensor(0.6000, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 1/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.647157\n",
      "epoch_acc tensor(0.6118, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.236714\n",
      "epoch_acc tensor(0.6083, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 2/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.525418\n",
      "epoch_acc tensor(0.6537, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.661534\n",
      "epoch_acc tensor(0.6500, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 3/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.459385\n",
      "epoch_acc tensor(0.6848, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.891854\n",
      "epoch_acc tensor(0.6844, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 4/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.527122\n",
      "epoch_acc tensor(0.6973, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.642625\n",
      "epoch_acc tensor(0.6967, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 5/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.388866\n",
      "epoch_acc tensor(0.7168, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.611332\n",
      "epoch_acc tensor(0.7160, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 6/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.403689\n",
      "epoch_acc tensor(0.7301, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.537790\n",
      "epoch_acc tensor(0.7304, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 7/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.418670\n",
      "epoch_acc tensor(0.7395, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.731401\n",
      "epoch_acc tensor(0.7375, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 8/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.470825\n",
      "epoch_acc tensor(0.7388, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.561591\n",
      "epoch_acc tensor(0.7389, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 9/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.357927\n",
      "epoch_acc tensor(0.7496, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.557013\n",
      "epoch_acc tensor(0.7479, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 10/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.388970\n",
      "epoch_acc tensor(0.7561, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.666487\n",
      "epoch_acc tensor(0.7553, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 11/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.367562\n",
      "epoch_acc tensor(0.7616, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.141324\n",
      "epoch_acc tensor(0.7604, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 12/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.416054\n",
      "epoch_acc tensor(0.7658, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.444288\n",
      "epoch_acc tensor(0.7657, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 13/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.448672\n",
      "epoch_acc tensor(0.7662, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.605971\n",
      "epoch_acc tensor(0.7658, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 14/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.413218\n",
      "epoch_acc tensor(0.7690, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.774339\n",
      "epoch_acc tensor(0.7678, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 15/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.444303\n",
      "epoch_acc tensor(0.7707, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.782715\n",
      "epoch_acc tensor(0.7703, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 16/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.439498\n",
      "epoch_acc tensor(0.7717, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.945997\n",
      "epoch_acc tensor(0.7708, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 17/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.463992\n",
      "epoch_acc tensor(0.7707, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.661092\n",
      "epoch_acc tensor(0.7694, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 18/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.390588\n",
      "epoch_acc tensor(0.7720, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.572012\n",
      "epoch_acc tensor(0.7721, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 19/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.383784\n",
      "epoch_acc tensor(0.7755, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.596773\n",
      "epoch_acc tensor(0.7752, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 20/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.348638\n",
      "epoch_acc tensor(0.7777, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.739363\n",
      "epoch_acc tensor(0.7778, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 21/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.253457\n",
      "epoch_acc tensor(0.7833, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.530233\n",
      "epoch_acc tensor(0.7828, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 22/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.344855\n",
      "epoch_acc tensor(0.7846, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.712206\n",
      "epoch_acc tensor(0.7842, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 23/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.367778\n",
      "epoch_acc tensor(0.7870, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.455032\n",
      "epoch_acc tensor(0.7873, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 24/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.277154\n",
      "epoch_acc tensor(0.7912, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.686357\n",
      "epoch_acc tensor(0.7907, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 25/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.403450\n",
      "epoch_acc tensor(0.7920, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.720170\n",
      "epoch_acc tensor(0.7913, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 26/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.368020\n",
      "epoch_acc tensor(0.7934, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.632665\n",
      "epoch_acc tensor(0.7934, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 27/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.337566\n",
      "epoch_acc tensor(0.7953, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.694950\n",
      "epoch_acc tensor(0.7946, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 28/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.270798\n",
      "epoch_acc tensor(0.7980, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.789248\n",
      "epoch_acc tensor(0.7976, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 29/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.337187\n",
      "epoch_acc tensor(0.7996, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.669025\n",
      "epoch_acc tensor(0.7996, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 30/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.245818\n",
      "epoch_acc tensor(0.8030, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.643078\n",
      "epoch_acc tensor(0.8028, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 31/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.309445\n",
      "epoch_acc tensor(0.8047, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.548405\n",
      "epoch_acc tensor(0.8044, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 32/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.358789\n",
      "epoch_acc tensor(0.8053, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.457794\n",
      "epoch_acc tensor(0.8054, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 33/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.290245\n",
      "epoch_acc tensor(0.8078, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.782566\n",
      "epoch_acc tensor(0.8074, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 34/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.211472\n",
      "epoch_acc tensor(0.8104, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.165201\n",
      "epoch_acc tensor(0.8098, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 35/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.167082\n",
      "epoch_acc tensor(0.8136, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.272771\n",
      "epoch_acc tensor(0.8133, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 36/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.272505\n",
      "epoch_acc tensor(0.8154, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.462779\n",
      "epoch_acc tensor(0.8154, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 37/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.316330\n",
      "epoch_acc tensor(0.8168, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.344752\n",
      "epoch_acc tensor(0.8168, device='cuda:0', dtype=torch.float64)\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 38/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.290295\n",
      "epoch_acc tensor(0.8181, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.497595\n",
      "epoch_acc tensor(0.8181, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 39/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.235203\n",
      "epoch_acc tensor(0.8203, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.702172\n",
      "epoch_acc tensor(0.8202, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 40/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.260837\n",
      "epoch_acc tensor(0.8220, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.605465\n",
      "epoch_acc tensor(0.8220, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 41/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.241469\n",
      "epoch_acc tensor(0.8233, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.816646\n",
      "epoch_acc tensor(0.8228, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 42/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.267815\n",
      "epoch_acc tensor(0.8244, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.043368\n",
      "epoch_acc tensor(0.8237, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 43/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.356539\n",
      "epoch_acc tensor(0.8242, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.088586\n",
      "epoch_acc tensor(0.8237, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 44/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.348777\n",
      "epoch_acc tensor(0.8241, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.846085\n",
      "epoch_acc tensor(0.8236, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 45/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.270254\n",
      "epoch_acc tensor(0.8248, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.666411\n",
      "epoch_acc tensor(0.8246, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 46/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.267525\n",
      "epoch_acc tensor(0.8258, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.962403\n",
      "epoch_acc tensor(0.8255, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 47/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.249184\n",
      "epoch_acc tensor(0.8265, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.514610\n",
      "epoch_acc tensor(0.8264, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 48/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.208353\n",
      "epoch_acc tensor(0.8283, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.571534\n",
      "epoch_acc tensor(0.8281, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 49/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.223925\n",
      "epoch_acc tensor(0.8300, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.581076\n",
      "epoch_acc tensor(0.8297, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 50/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.238548\n",
      "epoch_acc tensor(0.8310, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.473825\n",
      "epoch_acc tensor(0.8310, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 51/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.136507\n",
      "epoch_acc tensor(0.8333, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.608321\n",
      "epoch_acc tensor(0.8334, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 52/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.190992\n",
      "epoch_acc tensor(0.8350, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.710604\n",
      "epoch_acc tensor(0.8347, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 53/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.277420\n",
      "epoch_acc tensor(0.8355, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.079055\n",
      "epoch_acc tensor(0.8352, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 54/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.279572\n",
      "epoch_acc tensor(0.8361, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.508426\n",
      "epoch_acc tensor(0.8360, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 55/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.181961\n",
      "epoch_acc tensor(0.8371, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.663953\n",
      "epoch_acc tensor(0.8369, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 56/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.158357\n",
      "epoch_acc tensor(0.8387, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.716146\n",
      "epoch_acc tensor(0.8385, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 57/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.198068\n",
      "epoch_acc tensor(0.8397, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.652133\n",
      "epoch_acc tensor(0.8396, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 58/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.179613\n",
      "epoch_acc tensor(0.8408, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.679078\n",
      "epoch_acc tensor(0.8409, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 59/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.206840\n",
      "epoch_acc tensor(0.8422, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.688210\n",
      "epoch_acc tensor(0.8421, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 60/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.197403\n",
      "epoch_acc tensor(0.8433, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.957786\n",
      "epoch_acc tensor(0.8432, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 61/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.176612\n",
      "epoch_acc tensor(0.8445, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.807759\n",
      "epoch_acc tensor(0.8443, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 62/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.178634\n",
      "epoch_acc tensor(0.8453, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.562404\n",
      "epoch_acc tensor(0.8451, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 63/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.169150\n",
      "epoch_acc tensor(0.8466, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.263488\n",
      "epoch_acc tensor(0.8463, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 64/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.125787\n",
      "epoch_acc tensor(0.8478, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.970015\n",
      "epoch_acc tensor(0.8477, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 65/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.153476\n",
      "epoch_acc tensor(0.8490, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.836310\n",
      "epoch_acc tensor(0.8487, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 66/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.075691\n",
      "epoch_acc tensor(0.8505, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.661177\n",
      "epoch_acc tensor(0.8504, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 67/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.181441\n",
      "epoch_acc tensor(0.8513, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.636052\n",
      "epoch_acc tensor(0.8512, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 68/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.218457\n",
      "epoch_acc tensor(0.8521, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.888077\n",
      "epoch_acc tensor(0.8521, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 69/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.243689\n",
      "epoch_acc tensor(0.8524, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.855127\n",
      "epoch_acc tensor(0.8523, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 70/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.314321\n",
      "epoch_acc tensor(0.8526, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.603189\n",
      "epoch_acc tensor(0.8526, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 71/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.217961\n",
      "epoch_acc tensor(0.8534, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.652431\n",
      "epoch_acc tensor(0.8534, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 72/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.260754\n",
      "epoch_acc tensor(0.8541, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.699287\n",
      "epoch_acc tensor(0.8541, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 73/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.160586\n",
      "epoch_acc tensor(0.8552, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.721380\n",
      "epoch_acc tensor(0.8552, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 74/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.119021\n",
      "epoch_acc tensor(0.8564, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.052231\n",
      "epoch_acc tensor(0.8562, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 75/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.152127\n",
      "epoch_acc tensor(0.8573, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.752358\n",
      "epoch_acc tensor(0.8570, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 76/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.175660\n",
      "epoch_acc tensor(0.8579, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.667476\n",
      "epoch_acc tensor(0.8578, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 77/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.133627\n",
      "epoch_acc tensor(0.8589, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.751345\n",
      "epoch_acc tensor(0.8588, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 78/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.103076\n",
      "epoch_acc tensor(0.8601, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.697066\n",
      "epoch_acc tensor(0.8600, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 79/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.138634\n",
      "epoch_acc tensor(0.8609, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.406701\n",
      "epoch_acc tensor(0.8607, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 80/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.129146\n",
      "epoch_acc tensor(0.8616, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.944582\n",
      "epoch_acc tensor(0.8614, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 81/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.160233\n",
      "epoch_acc tensor(0.8624, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.679140\n",
      "epoch_acc tensor(0.8621, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 82/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.097533\n",
      "epoch_acc tensor(0.8632, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.564302\n",
      "epoch_acc tensor(0.8631, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 83/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.114114\n",
      "epoch_acc tensor(0.8641, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.880404\n",
      "epoch_acc tensor(0.8639, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 84/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.224044\n",
      "epoch_acc tensor(0.8644, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.689075\n",
      "epoch_acc tensor(0.8644, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 85/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.070027\n",
      "epoch_acc tensor(0.8656, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.725344\n",
      "epoch_acc tensor(0.8656, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 86/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.113741\n",
      "epoch_acc tensor(0.8667, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.156395\n",
      "epoch_acc tensor(0.8666, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 87/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.106828\n",
      "epoch_acc tensor(0.8675, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.473062\n",
      "epoch_acc tensor(0.8672, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 88/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.115593\n",
      "epoch_acc tensor(0.8683, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.830770\n",
      "epoch_acc tensor(0.8682, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 89/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.169166\n",
      "epoch_acc tensor(0.8689, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.145946\n",
      "epoch_acc tensor(0.8688, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 90/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.122428\n",
      "epoch_acc tensor(0.8696, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.563044\n",
      "epoch_acc tensor(0.8695, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 91/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.113974\n",
      "epoch_acc tensor(0.8704, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.890617\n",
      "epoch_acc tensor(0.8703, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 92/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.105744\n",
      "epoch_acc tensor(0.8711, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.775652\n",
      "epoch_acc tensor(0.8711, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 93/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.074750\n",
      "epoch_acc tensor(0.8720, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.793174\n",
      "epoch_acc tensor(0.8719, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 94/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.072303\n",
      "epoch_acc tensor(0.8728, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.668513\n",
      "epoch_acc tensor(0.8727, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 95/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.146912\n",
      "epoch_acc tensor(0.8733, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.622067\n",
      "epoch_acc tensor(0.8733, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 96/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.173414\n",
      "epoch_acc tensor(0.8738, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.661259\n",
      "epoch_acc tensor(0.8736, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 97/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.096285\n",
      "epoch_acc tensor(0.8744, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 1.302865\n",
      "epoch_acc tensor(0.8743, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 98/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.101878\n",
      "epoch_acc tensor(0.8752, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.927498\n",
      "epoch_acc tensor(0.8750, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Epoch 99/99\n",
      "----------\n",
      "LR 0.001\n",
      "train: loss: 0.160010\n",
      "epoch_acc tensor(0.8758, device='cuda:0', dtype=torch.float64)\n",
      "val: loss: 0.811819\n",
      "epoch_acc tensor(0.8757, device='cuda:0', dtype=torch.float64)\n",
      "0m 1s\n",
      "Best val loss: 0.344752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#wiith drop out and batch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "model4 = Resnet.resnet(batchNormalization=True, dropOut= True).to(device)\n",
    "model4.float()\n",
    "print(model4.children)\n",
    "\n",
    "\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model4.parameters()), lr=1e-3)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer_ft, \"min\", factor=0.8, patience=10, verbose=True)      \n",
    "              \n",
    "model4,tain_acc4,val_acc4 = train_model(model4, optimizer_ft, lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6601,
     "status": "ok",
     "timestamp": 1593195861918,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "ehkKxY9wkk_b",
    "outputId": "b9fcc678-e316-4f41-cba6-0b1df11e8682"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#A\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(4,1,1)\n",
    "plt.title('train without dropout')\n",
    "plt.plot(tain_acc1)\n",
    "plt.plot(tain_acc2)\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.title('val without dropout')\n",
    "plt.plot(val_acc1)\n",
    "plt.plot(val_acc2)\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.title('train with dropout')\n",
    "plt.plot(tain_acc3)\n",
    "plt.plot(tain_acc4)\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.title('val with dropout')\n",
    "plt.plot(val_acc3)\n",
    "plt.plot(val_acc4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kyv69fA6IIpT"
   },
   "source": [
    "می‌توان دید با اضافه کردن این لایه دقت به  میزان زیادی با وجود لایه‌ی دراپ‌‌ات و بدون آن هم در ترین و هم در ولیدیشن افزایش یافته است.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6596,
     "status": "ok",
     "timestamp": 1593195861918,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "50QKJMdz3Ole",
    "outputId": "a469a61a-1ffa-4df6-801b-748e849ba1aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABeCAYAAAAt6t8EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfSklEQVR4nO2deZhcVZn/P2/tXb1v2TrpdEISIERlyYRIHEVFFvkp+htUxBF0BHTUcRwdF0bnpzJuM+qMqDwoLozAAAr6QEQHxlFZZUkgrAlkX7qT9JLea6+67++Pc6q70unudNLdqaT6fJ7nPlV3O/c9y/2e97733nNFVXE4HA5H6eIrtgEOh8PhmF6c0DscDkeJ44Te4XA4Shwn9A6Hw1HiOKF3OByOEscJvcPhcJQ4TuhnCCJyroi0TjKNZhEZFBH/ONuoiCyZzHFOBERkp4icV2w7poKRbUNEXhKRc6fhOIMisniq03UcHif0jgmjqrtVtUJVcwAi8qCIXHUsji0iXxaR2w6zzU4RSVhB6RGR34rIggmm32I7qcDUWHxQ2h+waX92xPLW6RDUyaKqp6nqg5NJY7S2YdvO9kkZ5zgqnNA7So23qWoFMBdoB75fZHvydAOfFZHKySY0HZ2Ro7RxQn8CISKfE5G7Ryy7XkS+Z/9/UEQ2iciAiGwXkQ9PMN2viMj37f+giMRE5Ft2vkxEkiJSV+j1isjXgL8EfmA96B8UJHmeiGwRkV4RuUFExKblE5EvisguEekQkVtEpNquOyS0lA+PiMiFwD8B77HHeu5weVLVJHA3sLwgvYtFZIOI9IvIHhH5csEuD9vfXnuM19p9ri4o040icmbBPqeLyPMi0icivxCRyDgmbQIeBz412koRCYvId0Vkr52+KyLhwrKx9b8fuNle4dwlIrdZ214QkWUicq0t2z0icn5B+hNuG4VhKVuHg3aK2fpvEZFaEblPRDrt1dN9IjLf7jNq25CCsJ6IVNv677Tt4Ysi4rPrPiAij4rIt23aO0TkonHK1nE4VNVNJ8gELATiQKWd9wP7gNV2/mLgJECAN9htz7TrzgVax0j3TcAL9v85wDbgyYJ1z9n/LYACATv/IHDViLQUuA+oAZqBTuBCu+5vgK3AYqAC+DVw61j2ATuB8+z/LwO3HaZ8CrePAj8HbilYfy7wKoyD82qMx/+O0fJml70LaAP+wpbpEmBhwbGeAuYBdRgh/8gYdn0AeBQ4HegB6uzyVuBc+/864AlgFtAI/Bn4lwK7s8C/AmGgzJZHErgACAC3ADuALwBB4GpgR4ENE24bheU4Ih9fx3SIQaAe+CtbzpXAXcA9BduO1TaW2P+3APfafVuAzcCHCsorY/PgB/4W2AtIsc/BE3VyHv0JhKruAp4B3mkXvQmIq+oTdv1vVXWbGh4C/gfjWR2Ox4GlIlIPvB74KdAkIhUYUXjoCE39pqr2qupu4E8YgQN4H/DvqrpdVQeBa4HLpjgUcY+I9AJ9wFuAb+VXqOqDqvqCqnqq+jxwByZ/Y3EV8G+qus6W6VZbB3m+p6p7VbUb+A3D+RwVVX0W+D3wuVFWvw+4TlU7VLUT+Arw/oL1HvAlVU2pasIue0RVH1DVLEZoGzFlnwHuBFpEpMYe+2jbBgAi8h7gcuCvVDWjqgdU9VeqGlfVAeBrjF+WhWn5gcuAa1V1QFV3At8Zkd9dqvpjNfeDfo4Jxc2eqL2Og3FCf+JxO/Be+/9yOw+AiFwkIk+ISLcVu7cCDYdL0ArHesyJ+nqMsP8ZWMPRCf3+gv9xjPcOxvstFMpdGG90Kk/gd6hqDRABPg48JCJzAETkbBH5kw0X9AEfYfzyWYC5uhmLsfI5Hv8P+FsRGZnn0cpmXsF8p5pwVCHtBf8TQJcVxvw8eZuOtm3Yfc8AfgC803ZCiEhURH5kwy79GE+/RsZ5IquABsxVwcj8NhXMD5WtqsYL8+I4cpzQn3jcBZxr46HvxAq9jef+Cvg2MNuK3e8wl+oT4SHMFcIZwDo7fwGwiuH49UiOdOjTvZjwU55mTEiiHYhhwgDAkNfXeLTHUtWcqv4ayAGvs4tvB9YCC1S1Gvghw+UzWvp7MOGOKUNVX8aErL4wYtVoZbO3cNejPeZk2oaIzALuAT6mqhsKVn0aOBk4W1WrMA4CjF+eebowoZmR+W07fG4cR4MT+hMM61E9CNyMicFusqtCmPhtJ5C1N6/OHzWR0XkIuALYqKppe4yr7DE6x9inHRNvnyh3AP8gIotsWOjrwC9s6GEzELE3TIPAF21+Co/Vkr9hdzjEcAlQi4mfg4kHd6tqUkRWYa6I8nRiwiOF+fkJ8I8icpZNb4mIFIrT0fIV4IOY+xh57gC+KCKNItKA8fzHfZz0CDiqtmFDandj7o38csTqSsxVQ6+I1AFfGrF+zLZhrzp+CXxNRCptmX6KqcuvYwRO6E9MbgfOoyBsY+Okn8CcQD0YEVt7BGn+GXOTL++9b8Tc7BvLmwe4HrjUPhnxvQkc42fArTbNHTb9v7P29wEfxYhrG8bDL3wK5y77e0BEnhnnGL8RkUGgHxM3vlJVX7LrPgpcJyIDGCEdEi8bHvga8Jh90mS1qt5ll90ODGA827oJ5HNcVHUHphzKCxZ/FRM+ex54AXMv5quTPZY93tG2jfmYOP4nC568GRSRZuC7mPbShbmJfP+IfQ/XNv4OU8fbMTeqb8e0D8c0IKruwyMOh8NRyjiP3uFwOEocJ/QOh8NR4jihdzgcjhLHCb3D4XCUOE7oHQ6Ho8Q57kbBa2ho0JaWlmKb4XA4HMcWVdAc+I5Olp9++ukuVW0cbd1xJ/QtLS2sX7++2GY4HA7H9OB50PUKtK6HtqehazP07IKBvTB/FXzogaNKVkR2jbVuQkIvZpjY6zEjyf1EVb85yjbvxoyop5jRDi+3y3OYF0AAdqvq24/IeofD4TiRyGWgYyPsew7690L8AMS6YGA/9LfBwD7Ipc224WqYdSq0vA5qF8Ks5eOnfZQcVujtmCM3YEYCbAXWichaVd1YsM1SzEiEa1S1x46PkSehquOO6udwOBwnHKrQvd145ge2Qs8O89u+EXKp4e0iNRCth8q5sOBsqJoHjSdD00qoXwK+6b9VOhGPfhWwVe0nwETkTuASzCvyea4GblDVHgBV7ZhqQx0Oh6NoqEK8G/Y9a6a9G2D3kxCzUic+qJ4PtYtg1dXQdCbMPR1qmsEfLK7tTEzomzCj+OVpBc4esc0yABF5DBPe+bKq5se+iIjIeswohd9U1XsmZ7LD4XBMI4le2P0E7HxkOPwysB8yseFtahfBSW+C5rONl16/FAKh4tl8GKbqZmwAWIr5Us184GEReZWq9mK+yNMm5uvvfxSRF1T1oDG+ReQa4BqA5ubmKTLJ4XA4RqAKqQGIdcJgB8S7TPy8rxU6X4aOTSYcg4I/BHNfY6ZlF5qQy5xXwdxXQ1ltsXNyRExE6NswH2DIM59Dx41uxXx6LgPsEJHNGOFfp6ptAKq6XUQexIx3fpDQq+pNwE0AK1eudKOsORyOw+N50LcHurbAgS3mBmcwaib1IB2D9CAMtkP3DhND72uDbOLQtMQP9SfB7NPg1e+BhefA/JUQLDv2+ZoGJiL06zCfmVuEEfjLOHgcbzDDt74X89HiBkwoZ7uI1GI+dZeyy9cA/zZl1jscjtLFy0HvbuNhp2OQTUEmbjzvvRtg3/MHh1PGIlQJdS3miZZlF0LFLKiYDeUNUN4IUft7HIdeJsthhV5VsyLyceABTPz9Z6r6kohcB6xX1bV23fkishHzRZ/PqOoBETkH+JGIeJi3cL9Z+LSOw+EoUVTNY4aF4pnsh+5t0LvHCHcmBpmE2c7Lmv+DHebxw/69RuALn17JE4yaEMoZfw2zl0PDMjMFyyAdN+mKH0LlZvKHQCb6obXS5Lgbj37lypXqXphyOIpILguD+43YBsJQOc88HihixDjZZ6ZUvxHvRLcJjwy2m1j3ga0mVJIehEAEwlWAmrj4eIjPeNqVc8wx6xebm5z1SyBSZdIKhKGqCXwT+TTtzEJEnlbVlaOtO+7ejC1ZenbCM7eYE8UfNF6GqvFkNAc1C2HeGTB7BQQjxbZ2cng5Ey8NRE4sTyodg0QPIMZuXxDClUZcjjYfnmfCDdmU8U4ziQIx3G7Wic9OfiNg/iBEqo2gVc2DsjrTXvxB83q8iLHRFzC2BSJm3eFs9HI2pm2f+U7HjDedS5nYde8uEyrp32vaZCE++4iglxk7fX/Y2Ft/EixcYzqHfGegnllev8S09XAFBMuNF+4PmvR9/hOrvZxAOKG37DoQI5PzWDKrcmoTPrANHvkOPHenacTBqD3p01ZMAoAMX6L6AtB4irkpNHuFvcv/GohO+gt25qTu2WVev+7YBJ2vmBO//iRoOgtmnWZO9H3PQvuLRkDKG01Ms6zOeFWRavM/Wm9s6m+D1qfNq9zd24YfRdOcEa9g1IhRXjzFCpk/aNZVzjFTTYu9AfYXh8ZKVe2l/DbzLHPeoxxsN5f5gx0mb2COEa2H2hYjKMEyU7bZtBGd/FuK6UFTB7mMeZyuv9WkORq+oAkBBMJGzIJlNr7bYMrC5zf587LDXu3APvN0RzY5dn0EIhCqANSIsKoR0lxmfEEdDfGb8gxFjX2FIprsM+UWPzBGumJe5qldaOqgeoF5Jryqydg/sN+8ng+m/sO2HeT/R+tMGwlXOaE+TnGhG+CPL7fz8ds3oAq3XbWKsxZOgaimBuHBb8ATN5qT7awPwppPGI9nJKpGMPdugLZnjMjuf3H45AJz8i0429xMWvJmc3Jl01bo2o0nmhfBTNx4jvnHyGId0L/PeHFedjjNqvlQs8AIfqJ7eLk/bF7L1hwMdpo0Rnp4I6mYbfapajKiEYoaG9JxK3Y6PGhTLmtENh0z9ufFGjViNe8MI565jNmme7sR5pEEykwnUTHbdib2GIPtpsMaTWQj1ebmW7jC5DMQNl57VRNUNxnhzqeTy0B6wJRjanC4w8jETFnHuky5ebZs8qGHauuJh6tsBxExopvvKPJeb+W8sd+KTMdMnfW3mbrNe95e1tiW7xyySTNlEnaK2zi1bQO5tO2ca00HWLcYGpZC3Um2DEIFVwmOE5nxQjczSujTWY+rbllPMpPj8lXNXLhiDnet38OX1r7EqXOriKdzdA2muOPq1axoqj66g6jC5vvhd58x3vKZV8IbvwCVs488rXg37H/evLSx7znY8bARXfEZsYp1YoYWGg0x3mJ5g33KYJaJdzYsMyd6wzLjoedt7tlpxueoaTZXFIVv8+WfPU72QbLXCE+sy3iI5Q3mVe7q+ZMTi0QP7HzM5HHfsyaPvoARybrF0LjMXPaXNw57lOHKsY/peaaDy6WtoIdMeRwHbyk6HGPheYrPd3TnkRN6yzf+exM/emg7TTVltPUmqAgHGExlOe/UWVx/2Rn0JjK868Y/k8x6/PLDq48sjNPxMrx4N7z4K+OBNp4Kb/suNK+eugx4nvH6N/+3uZzOe6EVc4yHX1ZrxtUIRac0Pp7NeXQOpujoT9E5kCKWzpLM5EhlPfriGboGU3TF0kQCfpbMqmDJrAoW1keZVRmmuiyIOG/RUeKoKpmcksrm6I6l6Rww50pvIsNAMsNA0pwzmZySznkk0zkGUlliqSz9yQy98Qx98Qynzq3ilx957VHZMCOEPpbK8q0HXhmaF4GLVsxl1SIThnl0Sxd//dMnufzsZr56yQoe336AX6zbw7yaMj5zwcn4bS+6oyvGu374OKDccPmZnL24HjA97W1P7uLRLV187I1LeM2CGnOgbBoeuBbW/cR4oYteDysuNS9dBEK09yfpGkwxmMwSz+RoqS9nYV30kF47m/OIpXPE01lUIRTwEQr46OhPsbl9gFf2DzCQzBIO+ggHfAQK9q8IB1g+r5rl86qoCB962yXnKbu747zQ1scLrb1s74wRDQeoKQtSWx5ifm0ZC+uiLKiLImKufAZTWZ7a0c1Dmzt5YvsBkhlvzLKvigRoqAgzmMrSMXDw43ChgI/5tWWcPr+G05trOLO5luVzq47aa5kMOU+Jp7PE0znSWY+sp+Q8j75EhrbeJG09Cdr7k/TG0/TEM6SzHnUVIRrKQ1SXBfEUcqpkbPkMJLMkMjlqoyEaK8M0VISoCAeIhgNEAj7i6Ry98TT9SRMuC/iFkN9HeThAdVmQykiAvkSGPd0J9vTESWc9wgEf4YCf8rCfqkiQqrIAVZEg1dEgNWUmfb9fCPqEdM6jYyBFR3+SvkQGQYb69nTOI531yHlKVSRITTRITTREJOgj6DdTxm6TynrEUlkGUlkGbZ6Sdsp6iucpnio5D7KeKTcAn4BPhEjQT1UkMFRG+/uTtPcl6bftNRLwEwn6TNmEAgT8Qm88TXcsQ088TX8iQ38yQzLj0VwXHXIUemJpWnsS7OtLoigBnw+fTyhsOgGfEPT7CPh9eJ6Synqksjn8Phk6bijgw+8bPmcyOY9MTsnkPLKe+a9q0g/4TXpi81bo5PQmMlRFAtSXh6mMBOiOp+noT9E1mCKVHfv8yJdVJOgfsrcs5KciHKAiHKAyEqA2GqI6GmRxYwXvX73wqNr3jBD67liaN377waH5VDZHMuNx6Vnz+cgbFnP5j5+kqizIbz7+OspC4z+atbVjkGtuXc/uA3G+cPGpnH/aHD5793M8tvUA4YCPVNbjnWc08bk1Vcy5/8PQ+hSs/iis+eRQiGZL+wDf+Z/N3P/S/kPSrwwHOHVuFTnVoZ4/kRk/Bi4C5aEA6axHOjd6oxKBedVl1JWHqIkG8fuE3d1x9nTHyeRMPYcCPhY3lJPKevTE0/QlMozXBBY3lPP6ZY0snV3B7MoIjZVhqsqChG1HVBUJEgoMx5n7Ehm2dQ7S2pOgcyBFx0CSbR0xnt3TS9eg6QTqykOsWdLAqkV1NNVEmF0Vob48bIQn55HNKX6fEPQLAb+PoM/++oXyUGCok0hlc+zsirO9c5DBVHbIo9p1IM4r+wfY3D5Af9LkTzFCfzjKQ37qKkLURkOE/D66Y2m6BlP0J7P4BPw+IeDzURkxJ2gk6KcnlqZzMDVUxkdDbTRINBQYEth4JjduvRwLRCDoGxa9gE/w+8UKpqCq5FStzcNtMuATZldFqIwESOc8UhmPRCZHLJUdEsSyoH+onVaXBamKBAkGfOw6EGNrxyDxdA6fwJyqCHNryvD7hJynppOxBZOv07xw+wRCAT+hgA+1diUyOTJZY2fOM4Ke7+jy7SvgEyPqnml7Gc8zbUbNLZSGijCzKyPURIP0JzN0x9L0J7LUlgeZXRmhoTJMWdAcN+gX6srDQx1/XXmIykiQ8pB/2q9sZ4TQjySRzvG9P27hxw9vJ+spIb+Pez62huXzqia0f38yw6d+8Rz/u6mdoO3lv3TREt5W+QpPrH+Ktu2buEgep8KX5vmzvs6SN76fvb0JNrcP8MiWLu59to1oKMDfrGnhtKZqKsIBwgEf2zoHeaGtj037BggHfLZBhKkpCxINB4iG/AjDHllNNMQpcyo5qbFiqIPybIPPt5vuWJqX9vbxYls/O7pi9MbT9CaMR9pcF2VhfTmLGqKsaKpm2exKgv5hYc7kPNp6EuzqjtPWk0CEIa/yVU3VNNdHJ10XYC5t9/YleXL7AR7d0sUjW7voHBjlZZjDIIL1DP10DqQYTbvLgn6WzanklNmV1FWEELtfyG885bKQn5A92f0+oSIcoKm2jLnVESojo8fwVXXcE1VV6U9kiaWzxNNZkhmPaMhPTTREVSSAiAx1ZLFUlr5Ehv5ElspIgAV10UOuxDxPiaWz9Cez9MUz9CUy9CXSDKZy5KwXmhfUxsowteWhof1UIRz0EfIbD7g/kRnq1NNZ064ynhL0CaGCK4jKSIDycIBoMEAkZPafqDilsjn6EuaJnoby8JhXbNmcuSKIBMd2tjxPORBLUxMNHtRWHeMzI4U+z+b2Ab71wCtccNocLj1r/hHt63nKDx/exobdvfzzRctovv8DsO0PZl2ogtbwEj6X/CCPDxz89a5I0McVr23hI284ibry0n2tejKoKvv6kuzrS9Len6Q7lrai4yPg8w15V/lQQdZeag8kjUgOprLMrY6wZFYFJzVWUF1mriwCPqE2GipKaMjhKCYzWuinBFX47adh/U/hgm/Aq9899Kag5ynrd/Wwflc3C+vKOXlOBQvry50n4nA4jinuzdjJ8sSNRuTP+QS89qMHrfL5hFWL6oZu+jocDsfxhhP6PPFu8+hi/lX1ZP/wizcbboNT3wbnfaXYVjocDscR44QezHCn/3WpEfaRROvh5LfCO286Jt92dDgcjqnGCf32h+DO95m3RN/3KyivN29Shivtq/XuZqrD4TixmZCLKiIXisgrIrJVRD4/xjbvFpGNIvKSiNxesPxKEdlipyunyvApYdNvjCdfPR8+9HtYep4dQXK5GQPGibzD4SgBDuvRi4gfuAF4C+aTgetEZG3hB0REZClwLbBGVXtEZJZdXgd8CViJeb/habtvz9Rn5QjxPDMeTeMpcMW9UzM6pMPhcByHTMSjXwVsVdXtqpoG7gQuGbHN1cANeQFX1Q67/ALg96rabdf9HrhwakyfJK3rzKiJ53zCibzD4ShpJiL0TcCegvlWu6yQZcAyEXlMRJ4QkQuPYN/isPFeM0TrsguKbYnD4XBMK1N1MzYALAXOBeYDD4vIqya6s4hcA1wD0NzcPEUmjYOqEfqT3jw8VK/D4XCUKBPx6NuABQXz8+2yQlqBtaqaUdUdwGaM8E9kX1T1JlVdqaorGxsbR66eetqeMV8UWj4yAuVwOBylx0SEfh2wVEQWiUgIuAxYO2KbezDePCLSgAnlbAceAM4XkVoRqQXOt8umnmQ/rL/ZfC3pcGy8x3zU4uTj43aBw+FwTCeHFXpVzQIfxwj0JuCXqvqSiFwnIm+3mz0AHBCRjcCfgM+o6gFV7Qb+BdNZrAOus8umHi8L930SNo3sgw7JkAnbLD7XfKjD4XA4SpzSGtTsxjXm03ZX3Dv2NnufhZveAG//Ppx5xdEdx+FwOI4zxhvUrLTe6W95Hex+0nz1aSw23gvih5MvPnZ2ORwORxEpPaHPJmDvM6OvP7ANNtwKi/7SDHXgcDgcM4DSEvqFa8zvzkcOXdf5Ctx8kYnRX/D1Y2uXw+FwFJHSEvpoHcxeATsfO3h5+0tw81uNyH/gtzD7tOLY53A4HEWgtIQeTPhmT0GcPh2DW/8v+IPwwd/BrFOKa5/D4XAcY0pT6DNx8xERgKdugsH98K7/hIalRTXN4XA4ikHpCX3zOeZ35yPmJarHroclb4Hm1cW1y+FwOIpE6X14pLweZp0GOx8FLweJHnjjPxXbKofD4SgapSf0YMI3G241Y9qcfDE0nVlsixwOh6NolF7oBobj9Kk+5807HI4ZT2l69AvXgPjg1LfDnBXFtsbhcDiKSmkKfXk9XLHWibzD4XBQqkIPZpgDh8PhcBx/o1eKSCewaxJJNABdU2TOicJMzDPMzHzPxDzDzMz3keZ5oaqO+uWm407oJ4uIrB9rqM5SZSbmGWZmvmdinmFm5nsq81yaT904HA6HYwgn9A6Hw1HilKLQ31RsA4rATMwzzMx8z8Q8w8zM95TlueRi9A6Hw+E4mFL06B0Oh8NRQMkIvYhcKCKviMhWEfl8se2ZLkRkgYj8SUQ2ishLIvL3dnmdiPxeRLbY39pi2zrViIhfRDaIyH12fpGIPGnr/BciEiq2jVONiNSIyN0i8rKIbBKR15Z6XYvIP9i2/aKI3CEikVKsaxH5mYh0iMiLBctGrVsxfM/m/3kROaIBvEpC6EXED9wAXAQsB94rIsuLa9W0kQU+rarLgdXAx2xePw/8QVWXAn+w86XG3wObCub/FfgPVV0C9AAfKopV08v1wP2qegrwGkz+S7auRaQJ+ASwUlVXAH7gMkqzrv8TuHDEsrHq9iJgqZ2uAW48kgOVhNADq4CtqrpdVdPAncAlRbZpWlDVfar6jP0/gDnxmzD5/bnd7OfAO4pj4fQgIvOBi4Gf2HkB3gTcbTcpxTxXA68HfgqgqmlV7aXE6xrzxn6ZiASAKLCPEqxrVX0Y6B6xeKy6vQS4RQ1PADUiMneixyoVoW8C9hTMt9plJY2ItABnAE8Cs1V1n121H5hdJLOmi+8CnwU8O18P9Kpq1s6XYp0vAjqBm23I6iciUk4J17WqtgHfBnZjBL4PeJrSr+s8Y9XtpDSuVIR+xiEiFcCvgE+qan/hOjWPUpXM41Qi8n+ADlV9uti2HGMCwJnAjap6BhBjRJimBOu6FuO9LgLmAeUcGt6YEUxl3ZaK0LcBCwrm59tlJYmIBDEi/1+q+mu7uD1/KWd/O4pl3zSwBni7iOzEhOXehIld19jLeyjNOm8FWlX1STt/N0b4S7muzwN2qGqnqmaAX2Pqv9TrOs9YdTspjSsVoV8HLLV35kOYmzdri2zTtGBj0z8FNqnqvxesWgtcaf9fCdx7rG2bLlT1WlWdr6otmLr9o6q+D/gTcKndrKTyDKCq+4E9InKyXfRmYCMlXNeYkM1qEYnatp7Pc0nXdQFj1e1a4Ar79M1qoK8gxHN4VLUkJuCtwGZgG/CFYtszjfl8HeZy7nngWTu9FROz/gOwBfhfoK7Ytk5T/s8F7rP/FwNPAVuBu4Bwse2bhvyeDqy39X0PUFvqdQ18BXgZeBG4FQiXYl0Dd2DuQ2QwV28fGqtuAcE8WbgNeAHzVNKEj+XejHU4HI4Sp1RCNw6Hw+EYAyf0DofDUeI4oXc4HI4Sxwm9w+FwlDhO6B0Oh6PEcULvcDgcJY4TeofD4ShxnNA7HA5HifP/AdibcoCXeRTTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#B\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(4,1,1)\n",
    "plt.title('train without Batch Normalization')\n",
    "plt.plot(tain_acc1)\n",
    "plt.plot(tain_acc3)\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.title('val without Batch Normalization')\n",
    "plt.plot(val_acc1)\n",
    "plt.plot(val_acc3)\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.title('train with Batch Normalization')\n",
    "plt.plot(tain_acc2)\n",
    "plt.plot(tain_acc4)\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.title('val with Batch Normalization')\n",
    "plt.plot(val_acc2)\n",
    "plt.plot(val_acc4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6XCk4v7cIxTJ"
   },
   "source": [
    "می‌توان دید با افزودن آن در حالتی که بچ‌نرمالیزیشن وجود ندارد افزایش یافته. اما وقتی بچ‌نرمالیزیشن وجود دارد به دلیل اینکه خود بچ‌نرمالیزیشن یک رگیولایزر است دقت کمی کاهش می‌یابد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "ok",
     "timestamp": 1593195950097,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "S2Uvnir_xx1O",
    "outputId": "a0ac70f3-9ae1-4a01-bfcc-42b4e8553906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'Resnet.BasicBlock'>\n",
      "<class 'Resnet.BasicBlock'>\n",
      "<class 'Resnet.BasicBlock'>\n",
      "<class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Total convolutional layers: 7\n"
     ]
    }
   ],
   "source": [
    "#C\n",
    "model_children=list(model1.children())\n",
    "model_weights = []\n",
    "conv_layers = [] \n",
    "\n",
    "counter = 0 \n",
    "for i in range(len(model_children)):\n",
    "  print(type(model_children[i]))\n",
    "\n",
    "for i in range(len(model_children)):\n",
    "    if type(model_children[i]) == nn.Conv2d:\n",
    "        counter += 1\n",
    "        model_weights.append(model_children[i].weight)\n",
    "        conv_layers.append(model_children[i])\n",
    "    elif type(model_children[i]) == nn.Sequential:\n",
    "        for j in range(len(model_children[i])):\n",
    "            for child in model_children[i][j].children():\n",
    "                if type(child) == nn.Conv2d:\n",
    "                    counter += 1\n",
    "                    model_weights.append(child.weight)\n",
    "                    conv_layers.append(child)\n",
    "    else:\n",
    "        # print(list(model_children[i].children()))\n",
    "        for child in model_children[i].children():\n",
    "            if type(child) == nn.Conv2d:\n",
    "                counter += 1\n",
    "                model_weights.append(child.weight)\n",
    "                conv_layers.append(child)\n",
    "print(f\"Total convolutional layers: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1339,
     "status": "ok",
     "timestamp": 1593195954608,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "AP7-BP8-x35c",
    "outputId": "3f110cf0-9080-4398-e085-fe4dbdd6a4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV: Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) ====> SHAPE: torch.Size([8, 3, 3, 3])\n",
      "CONV: Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False) ====> SHAPE: torch.Size([16, 8, 7, 7])\n",
      "CONV: Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False) ====> SHAPE: torch.Size([16, 16, 7, 7])\n",
      "CONV: Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False) ====> SHAPE: torch.Size([32, 16, 5, 5])\n",
      "CONV: Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False) ====> SHAPE: torch.Size([32, 32, 5, 5])\n",
      "CONV: Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) ====> SHAPE: torch.Size([64, 32, 3, 3])\n",
      "CONV: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) ====> SHAPE: torch.Size([64, 64, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for weight, conv in zip(model_weights, conv_layers):\n",
    "    # print(f\"WEIGHT: {weight} \\nSHAPE: {weight.shape}\")\n",
    "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1593195957063,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "0-MzMV5H197s"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24721,
     "status": "ok",
     "timestamp": 1593196068223,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "3LTmce9ix8pW",
    "outputId": "2b8ac13c-d4ed-4fce-9e39-9dccb1e03633"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1224 with 64 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 17))\n",
    "for i, filter in enumerate(model_weights[6]):\n",
    "    plt.subplot(8, 8, i+1) \n",
    "    plt.imshow(filter[0, :, :].to(\"cpu\").detach(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('/content/filter7.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1439,
     "status": "ok",
     "timestamp": 1593196073144,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "Csl9SrJx8A4u",
    "outputId": "a4e1e008-8e2a-47bd-b707-6e755b292523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "s = dataset.__getitem__(0)\n",
    "print(s[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1593196226662,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "8MmfhHcY8gYw"
   },
   "outputs": [],
   "source": [
    "results = [conv_layers[0].to(\"cpu\")(s[0])]\n",
    "for i in range(1, len(conv_layers)):\n",
    "    results.append(conv_layers[i].to(\"cpu\")(results[-1]))\n",
    "outputs = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10063,
     "status": "ok",
     "timestamp": 1593196241868,
     "user": {
      "displayName": "Sana Ayromlou",
      "photoUrl": "",
      "userId": "16858211828516358070"
     },
     "user_tz": -270
    },
    "id": "QKdeBOZk8pak",
    "outputId": "283c994f-fe75-41f7-ead1-b9fdd3a891e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 64])\n",
      "Saving layer {0} feature maps...\n",
      "torch.Size([16, 64, 64])\n",
      "Saving layer {1} feature maps...\n",
      "torch.Size([16, 64, 64])\n",
      "Saving layer {2} feature maps...\n",
      "torch.Size([32, 32, 32])\n",
      "Saving layer {3} feature maps...\n",
      "torch.Size([32, 32, 32])\n",
      "Saving layer {4} feature maps...\n",
      "torch.Size([64, 16, 16])\n",
      "Saving layer {5} feature maps...\n",
      "torch.Size([64, 16, 16])\n",
      "Saving layer {6} feature maps...\n"
     ]
    }
   ],
   "source": [
    "for num_layer in range(len(outputs)):\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    layer_viz = outputs[num_layer][0, :, :, :]\n",
    "    layer_viz = layer_viz.data\n",
    "    print(layer_viz.size())\n",
    "    for i, filter in enumerate(layer_viz):\n",
    "        if i == 64: \n",
    "            break\n",
    "        plt.subplot(8, 8, i + 1)\n",
    "        plt.imshow(filter, cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "    print(\"Saving layer {\"+str(num_layer)+\"} feature maps...\")\n",
    "    plt.savefig(\"/content/layer_{\"+str(num_layer)+\"}.png\")\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bABRAoPfJh1Q"
   },
   "source": [
    "با مشاهده‌‌ی نتیجه و شکل‌ها می‌توان  فهمید که مپ های تشکیل شده در لایه‌های  اول واضح‌‌تر و در لایه‌های آخر ناواضح‌تر می‌‌باشد. در نتیجه در لایه‌های اول  به ویژگی‌های کلی مثل سایه‌ها و لبه‌ها توجه می‌کند ولی  در لایه های آخر  به ویژگی‌های اختصاصی‌تر مثل وجود  با عدم وجود تومور دقت ‌می‌‌کند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYqsrhkfKWyt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPXrfEdPJy+9iIZPufjVyNl",
   "collapsed_sections": [],
   "mount_file_id": "134INQtSK5M5Rx24wJz604UaEOwbCRoLU",
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
